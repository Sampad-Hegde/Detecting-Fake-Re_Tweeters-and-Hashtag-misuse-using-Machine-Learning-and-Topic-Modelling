{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models on Textual Features\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Classifier import get_KNN_Model, get_accuracy_matric, get_lin_SVM_Model, get_NaiveBayes_Model\n",
    "from Hawkes_Process import get_topic_vector\n",
    "from Topic_Modelling import LDA_main_driver\n",
    "from filters import train_test_splitter, get_users_dataframe\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-* LDA Training Started -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "\n",
      "\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-* LDA Training Ended -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df, dict_genuine, dict_fake, lda_genuine, lda_fake = LDA_main_driver()\n",
    "num_topics = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-* Hawkes Process Started -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "\n",
      "\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-* Hawkes Process Ended -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_topic_vectors, labels = get_topic_vector(df, dict_genuine, dict_fake, lda_genuine, lda_fake, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(user_topic_vectors)\n",
    "X = np.array(user_topic_vectors)\n",
    "Y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_probs = X[:,[range(0,20)]].reshape(X.shape[0],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1527, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_splitter(topic_probs, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrixPrint(P,Y,dataType):\n",
    "    TF = 0\n",
    "    TT = 0\n",
    "    FF = 0\n",
    "    FT = 0\n",
    "    for p,y in zip(P,Y):\n",
    "        if (p,y) == (0,0):\n",
    "            FF += 1\n",
    "        elif (p,y) == (1,1):\n",
    "            TT += 1\n",
    "        elif (p,y) == (0,1):\n",
    "            TF += 1\n",
    "        else:\n",
    "            FT += 1\n",
    "\n",
    "    print('------------------------------------------------------------------------------------\\n')\n",
    "    if dataType == 0:\n",
    "        print(\"  Confusion Matrix for Train Data : \")\n",
    "    else:\n",
    "        print(\"  Confusion Matrix for Validation Data \\n\")\n",
    "    print(\"         True Positive = \",TT,\"           True Negetive = \",TF)\n",
    "    print(\"        False Positive = \",FT,\"          False Negetive = \",FF)\n",
    "    print('\\n------------------------------------------------------------------------------------\\n')\n",
    "    total = TT+FF+TF+FT\n",
    "    print(f\"  Total Cases : {total}\\n\")\n",
    "    print(\"Accuracy  : \",(TT+FF)/total)\n",
    "    try:\n",
    "        prec = (TT)/(TT+FT)\n",
    "        recall = (TT)/(TT+TF)\n",
    "        f = (2*recall*prec)/(recall+prec)\n",
    "        print(\"Precision : \",prec)\n",
    "        print(\"Recall    : \",recall)\n",
    "        print(\"F1 Score  : \",f)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    print('\\n------------------------------------------------------------------------------------')\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. KNN Classifier on Topic Vectors Generated by LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = get_KNN_Model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Confusion Matrix for Train Data : \n",
      "         True Positive =  114            True Negetive =  81\n",
      "        False Positive =  31           False Negetive =  995\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Total Cases : 1221\n",
      "\n",
      "Accuracy  :  0.9082719082719083\n",
      "Precision :  0.7862068965517242\n",
      "Recall    :  0.5846153846153846\n",
      "F1 Score  :  0.6705882352941177\n",
      "\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pred = knn.predict(x_train)\n",
    "confusionMatrixPrint(pred,y_train,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Confusion Matrix for Validation Data \n",
      "\n",
      "         True Positive =  17            True Negetive =  23\n",
      "        False Positive =  11           False Negetive =  255\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Total Cases : 306\n",
      "\n",
      "Accuracy  :  0.8888888888888888\n",
      "Precision :  0.6071428571428571\n",
      "Recall    :  0.425\n",
      "F1 Score  :  0.5\n",
      "\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pred = knn.predict(x_test)\n",
    "confusionMatrixPrint(pred,y_test,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SVM Classifier on Topic Vectors Generated by LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = get_lin_SVM_Model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Confusion Matrix for Train Data : \n",
      "         True Positive =  27            True Negetive =  168\n",
      "        False Positive =  10           False Negetive =  1016\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Total Cases : 1221\n",
      "\n",
      "Accuracy  :  0.8542178542178542\n",
      "Precision :  0.7297297297297297\n",
      "Recall    :  0.13846153846153847\n",
      "F1 Score  :  0.23275862068965517\n",
      "\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pred = svm.predict(x_train)\n",
    "confusionMatrixPrint(pred,y_train,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Confusion Matrix for Validation Data \n",
      "\n",
      "         True Positive =  5            True Negetive =  35\n",
      "        False Positive =  1           False Negetive =  265\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Total Cases : 306\n",
      "\n",
      "Accuracy  :  0.8823529411764706\n",
      "Precision :  0.8333333333333334\n",
      "Recall    :  0.125\n",
      "F1 Score  :  0.21739130434782608\n",
      "\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pred = svm.predict(x_test)\n",
    "confusionMatrixPrint(pred,y_test,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Naive Bayes Classifier on Topic Vectors Generated by LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = get_NaiveBayes_Model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Confusion Matrix for Train Data : \n",
      "         True Positive =  87            True Negetive =  108\n",
      "        False Positive =  142           False Negetive =  884\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Total Cases : 1221\n",
      "\n",
      "Accuracy  :  0.7952497952497952\n",
      "Precision :  0.3799126637554585\n",
      "Recall    :  0.4461538461538462\n",
      "F1 Score  :  0.410377358490566\n",
      "\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pred = nb.predict(x_train)\n",
    "confusionMatrixPrint(pred,y_train,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Confusion Matrix for Validation Data \n",
      "\n",
      "         True Positive =  19            True Negetive =  21\n",
      "        False Positive =  30           False Negetive =  236\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Total Cases : 306\n",
      "\n",
      "Accuracy  :  0.8333333333333334\n",
      "Precision :  0.3877551020408163\n",
      "Recall    :  0.475\n",
      "F1 Score  :  0.42696629213483145\n",
      "\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pred = nb.predict(x_test)\n",
    "confusionMatrixPrint(pred,y_test,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Nueral Network Based Classifier on Topic Vectors Generated by LDA\n",
    "\n",
    "## Fully Connected Network of :\n",
    "     - Input Layer : 20, 64\n",
    "     - Hidden Layer 1 : 64 , 128\n",
    "     - Hidden Layer 2 : 128 , 256\n",
    "     - Hidden Layer 3 : 256 , 512\n",
    "     - Hidden Layer 4 : 512 , 256\n",
    "     - Hidden Layer 5 : 256 , 128\n",
    "     - Hidden Layer 6 : 128 , 64\n",
    "     - Hidden Layer 7 : 64 , 32\n",
    "     - Hidden Layer 8 : 32 , 16\n",
    "     - Output Layer : 16 , 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import warnings\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Device():\n",
    "    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = get_Device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.Tensor(x_train).to(device)\n",
    "y_train = torch.Tensor(y_train).to(device)\n",
    "x_test = torch.Tensor(x_test).to(device)\n",
    "y_test = torch.Tensor(y_test).to(device)\n",
    "y_train = y_train.to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkClassifierModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NeuralNetworkClassifierModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 64)\n",
    "        self.layer2 = nn.Linear(64, 128)\n",
    "        self.layer3 = nn.Linear(128, 256)\n",
    "        self.layer4 = nn.Linear(256, 512)\n",
    "        self.layer5 = nn.Linear(512, 256)\n",
    "        \n",
    "        self.layer6 = nn.Linear(256, 128)\n",
    "        self.layer7 = nn.Linear(128, 64)\n",
    "        self.layer8 = nn.Linear(64, 32)\n",
    "        self.layer9 = nn.Linear(32, 16)\n",
    "        self.layer10 = nn.Linear(16, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out = self.layer1(inputs)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.layer2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.layer3(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.layer4(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.layer5(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.layer6(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.layer7(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.layer8(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.layer9(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.layer10(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 20\n",
    "output_size = 2\n",
    "learning_rate = 0.0001\n",
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetworkClassifierModel(input_size=input_size,\n",
    "                                     output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetworkClassifierModel(\n",
       "  (layer1): Linear(in_features=20, out_features=64, bias=True)\n",
       "  (layer2): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (layer3): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (layer4): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (layer5): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (layer6): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (layer7): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (layer8): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (layer9): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (layer10): Linear(in_features=16, out_features=2, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfn = torch.nn.CrossEntropyLoss()\n",
    "lossfn.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Validator(x_test, y_test):\n",
    "    predicted = model(x_test).to(device)\n",
    "    pred = torch.max(predicted.data,1)[1]\n",
    "    total_test = len(y_test)\n",
    "    correct_pred = 0\n",
    "\n",
    "    for i in range(total_test):\n",
    "        if y_test[i] == pred[i]:\n",
    "            correct_pred += 1\n",
    "\n",
    "    return correct_pred/total_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 1 / 500 ] Training-Loss = 0.7790 Training-Accuracy = 0.2210078239440918 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 2 / 500 ] Training-Loss = 0.7785 Training-Accuracy = 0.22152233123779297 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 3 / 500 ] Training-Loss = 0.7780 Training-Accuracy = 0.222029447555542 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 4 / 500 ] Training-Loss = 0.7775 Training-Accuracy = 0.22252368927001953 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 5 / 500 ] Training-Loss = 0.7770 Training-Accuracy = 0.22301268577575684 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 6 / 500 ] Training-Loss = 0.7765 Training-Accuracy = 0.22350436449050903 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 7 / 500 ] Training-Loss = 0.7760 Training-Accuracy = 0.22399765253067017 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 8 / 500 ] Training-Loss = 0.7755 Training-Accuracy = 0.22449231147766113 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 9 / 500 ] Training-Loss = 0.7750 Training-Accuracy = 0.22498667240142822 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 10 / 500 ] Training-Loss = 0.7745 Training-Accuracy = 0.22547674179077148 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 11 / 500 ] Training-Loss = 0.7740 Training-Accuracy = 0.22596848011016846 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 12 / 500 ] Training-Loss = 0.7735 Training-Accuracy = 0.22646397352218628 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 13 / 500 ] Training-Loss = 0.7730 Training-Accuracy = 0.22696059942245483 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 14 / 500 ] Training-Loss = 0.7725 Training-Accuracy = 0.2274530529975891 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 15 / 500 ] Training-Loss = 0.7721 Training-Accuracy = 0.22794753313064575 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 16 / 500 ] Training-Loss = 0.7716 Training-Accuracy = 0.22844630479812622 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 17 / 500 ] Training-Loss = 0.7711 Training-Accuracy = 0.22894889116287231 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 18 / 500 ] Training-Loss = 0.7705 Training-Accuracy = 0.22945576906204224 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 19 / 500 ] Training-Loss = 0.7700 Training-Accuracy = 0.22996467351913452 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 20 / 500 ] Training-Loss = 0.7696 Training-Accuracy = 0.23041224479675293 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 21 / 500 ] Training-Loss = 0.7692 Training-Accuracy = 0.2307860255241394 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 22 / 500 ] Training-Loss = 0.7688 Training-Accuracy = 0.23116421699523926 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 23 / 500 ] Training-Loss = 0.7685 Training-Accuracy = 0.2315448522567749 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 24 / 500 ] Training-Loss = 0.7681 Training-Accuracy = 0.2319241166114807 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 25 / 500 ] Training-Loss = 0.7677 Training-Accuracy = 0.23230677843093872 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 26 / 500 ] Training-Loss = 0.7673 Training-Accuracy = 0.23269301652908325 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 27 / 500 ] Training-Loss = 0.7669 Training-Accuracy = 0.23308247327804565 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 28 / 500 ] Training-Loss = 0.7665 Training-Accuracy = 0.23347783088684082 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 29 / 500 ] Training-Loss = 0.7661 Training-Accuracy = 0.23388129472732544 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 30 / 500 ] Training-Loss = 0.7657 Training-Accuracy = 0.2342909574508667 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 31 / 500 ] Training-Loss = 0.7653 Training-Accuracy = 0.23470664024353027 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 32 / 500 ] Training-Loss = 0.7649 Training-Accuracy = 0.2351282238960266 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 33 / 500 ] Training-Loss = 0.7644 Training-Accuracy = 0.2355564832687378 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 34 / 500 ] Training-Loss = 0.7640 Training-Accuracy = 0.2359919548034668 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 35 / 500 ] Training-Loss = 0.7636 Training-Accuracy = 0.23643487691879272 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 36 / 500 ] Training-Loss = 0.7631 Training-Accuracy = 0.2368849515914917 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 37 / 500 ] Training-Loss = 0.7627 Training-Accuracy = 0.23734420537948608 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 38 / 500 ] Training-Loss = 0.7622 Training-Accuracy = 0.23781633377075195 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 39 / 500 ] Training-Loss = 0.7617 Training-Accuracy = 0.2382826805114746 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 40 / 500 ] Training-Loss = 0.7612 Training-Accuracy = 0.23876839876174927 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 41 / 500 ] Training-Loss = 0.7607 Training-Accuracy = 0.23927688598632812 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 42 / 500 ] Training-Loss = 0.7602 Training-Accuracy = 0.23980045318603516 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 43 / 500 ] Training-Loss = 0.7597 Training-Accuracy = 0.24033570289611816 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 44 / 500 ] Training-Loss = 0.7591 Training-Accuracy = 0.24088221788406372 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 45 / 500 ] Training-Loss = 0.7586 Training-Accuracy = 0.2414485216140747 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 46 / 500 ] Training-Loss = 0.7580 Training-Accuracy = 0.2420358657836914 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 47 / 500 ] Training-Loss = 0.7574 Training-Accuracy = 0.24264270067214966 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 48 / 500 ] Training-Loss = 0.7567 Training-Accuracy = 0.24327272176742554 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 49 / 500 ] Training-Loss = 0.7561 Training-Accuracy = 0.24392861127853394 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 50 / 500 ] Training-Loss = 0.7554 Training-Accuracy = 0.2446010708808899 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 51 / 500 ] Training-Loss = 0.7547 Training-Accuracy = 0.2452954649925232 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 52 / 500 ] Training-Loss = 0.7540 Training-Accuracy = 0.24602168798446655 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 53 / 500 ] Training-Loss = 0.7532 Training-Accuracy = 0.2467811107635498 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 54 / 500 ] Training-Loss = 0.7524 Training-Accuracy = 0.24758023023605347 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 55 / 500 ] Training-Loss = 0.7516 Training-Accuracy = 0.24841785430908203 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 56 / 500 ] Training-Loss = 0.7508 Training-Accuracy = 0.2492276430130005 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 57 / 500 ] Training-Loss = 0.7500 Training-Accuracy = 0.2499912977218628 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 58 / 500 ] Training-Loss = 0.7493 Training-Accuracy = 0.25074928998947144 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 59 / 500 ] Training-Loss = 0.7485 Training-Accuracy = 0.2515280246734619 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 60 / 500 ] Training-Loss = 0.7477 Training-Accuracy = 0.25230371952056885 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 61 / 500 ] Training-Loss = 0.7470 Training-Accuracy = 0.253021776676178 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 62 / 500 ] Training-Loss = 0.7463 Training-Accuracy = 0.25373876094818115 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 63 / 500 ] Training-Loss = 0.7455 Training-Accuracy = 0.2544938325881958 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 64 / 500 ] Training-Loss = 0.7447 Training-Accuracy = 0.255288302898407 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 65 / 500 ] Training-Loss = 0.7439 Training-Accuracy = 0.25612175464630127 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 66 / 500 ] Training-Loss = 0.7430 Training-Accuracy = 0.256999135017395 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 67 / 500 ] Training-Loss = 0.7421 Training-Accuracy = 0.25792479515075684 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 68 / 500 ] Training-Loss = 0.7411 Training-Accuracy = 0.2589079737663269 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 69 / 500 ] Training-Loss = 0.7400 Training-Accuracy = 0.25995850563049316 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 70 / 500 ] Training-Loss = 0.7389 Training-Accuracy = 0.26108187437057495 Validation-Accuracy = 0.13071895424836602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 71 / 500 ] Training-Loss = 0.7378 Training-Accuracy = 0.2622489929199219 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 72 / 500 ] Training-Loss = 0.7366 Training-Accuracy = 0.26343291997909546 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 73 / 500 ] Training-Loss = 0.7353 Training-Accuracy = 0.26469284296035767 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 74 / 500 ] Training-Loss = 0.7339 Training-Accuracy = 0.2660548686981201 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 75 / 500 ] Training-Loss = 0.7325 Training-Accuracy = 0.267520010471344 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 76 / 500 ] Training-Loss = 0.7309 Training-Accuracy = 0.2690735459327698 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 77 / 500 ] Training-Loss = 0.7293 Training-Accuracy = 0.27070915699005127 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 78 / 500 ] Training-Loss = 0.7276 Training-Accuracy = 0.2724449038505554 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 79 / 500 ] Training-Loss = 0.7257 Training-Accuracy = 0.27427661418914795 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 80 / 500 ] Training-Loss = 0.7238 Training-Accuracy = 0.2762216329574585 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 81 / 500 ] Training-Loss = 0.7217 Training-Accuracy = 0.2783191204071045 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 82 / 500 ] Training-Loss = 0.7194 Training-Accuracy = 0.2805991768836975 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 83 / 500 ] Training-Loss = 0.7169 Training-Accuracy = 0.28310155868530273 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 84 / 500 ] Training-Loss = 0.7143 Training-Accuracy = 0.2857404947280884 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 85 / 500 ] Training-Loss = 0.7120 Training-Accuracy = 0.28804951906204224 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 86 / 500 ] Training-Loss = 0.7096 Training-Accuracy = 0.2903531789779663 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 87 / 500 ] Training-Loss = 0.7071 Training-Accuracy = 0.2929394841194153 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 88 / 500 ] Training-Loss = 0.7041 Training-Accuracy = 0.29587727785110474 Validation-Accuracy = 0.13071895424836602\n",
      "Epoch [ 89 / 500 ] Training-Loss = 0.7008 Training-Accuracy = 0.29917216300964355 Validation-Accuracy = 0.17320261437908496\n",
      "Epoch [ 90 / 500 ] Training-Loss = 0.6972 Training-Accuracy = 0.3028174638748169 Validation-Accuracy = 0.5065359477124183\n",
      "Epoch [ 91 / 500 ] Training-Loss = 0.6932 Training-Accuracy = 0.3068288564682007 Validation-Accuracy = 0.8398692810457516\n",
      "Epoch [ 92 / 500 ] Training-Loss = 0.6888 Training-Accuracy = 0.3112409710884094 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 93 / 500 ] Training-Loss = 0.6839 Training-Accuracy = 0.31613975763320923 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 94 / 500 ] Training-Loss = 0.6784 Training-Accuracy = 0.32158350944519043 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 95 / 500 ] Training-Loss = 0.6725 Training-Accuracy = 0.32754671573638916 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 96 / 500 ] Training-Loss = 0.6660 Training-Accuracy = 0.3339692950248718 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 97 / 500 ] Training-Loss = 0.6591 Training-Accuracy = 0.3408779501914978 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 98 / 500 ] Training-Loss = 0.6516 Training-Accuracy = 0.3483993411064148 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 99 / 500 ] Training-Loss = 0.6434 Training-Accuracy = 0.356586217880249 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 100 / 500 ] Training-Loss = 0.6345 Training-Accuracy = 0.36551469564437866 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 101 / 500 ] Training-Loss = 0.6248 Training-Accuracy = 0.37524211406707764 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 102 / 500 ] Training-Loss = 0.6142 Training-Accuracy = 0.38582515716552734 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 103 / 500 ] Training-Loss = 0.6028 Training-Accuracy = 0.3971957564353943 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 104 / 500 ] Training-Loss = 0.5908 Training-Accuracy = 0.4092038869857788 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 105 / 500 ] Training-Loss = 0.5781 Training-Accuracy = 0.4218883514404297 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 106 / 500 ] Training-Loss = 0.5648 Training-Accuracy = 0.4352417588233948 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 107 / 500 ] Training-Loss = 0.5509 Training-Accuracy = 0.44910889863967896 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 108 / 500 ] Training-Loss = 0.5367 Training-Accuracy = 0.46334755420684814 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 109 / 500 ] Training-Loss = 0.5223 Training-Accuracy = 0.4777368903160095 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 110 / 500 ] Training-Loss = 0.5082 Training-Accuracy = 0.49181896448135376 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 111 / 500 ] Training-Loss = 0.4944 Training-Accuracy = 0.5055837333202362 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 112 / 500 ] Training-Loss = 0.4813 Training-Accuracy = 0.5187319815158844 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 113 / 500 ] Training-Loss = 0.4691 Training-Accuracy = 0.530895471572876 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 114 / 500 ] Training-Loss = 0.4583 Training-Accuracy = 0.541728138923645 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 115 / 500 ] Training-Loss = 0.4491 Training-Accuracy = 0.5509229302406311 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 116 / 500 ] Training-Loss = 0.4418 Training-Accuracy = 0.5581563115119934 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 117 / 500 ] Training-Loss = 0.4368 Training-Accuracy = 0.5632311701774597 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 118 / 500 ] Training-Loss = 0.4339 Training-Accuracy = 0.5660924315452576 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 119 / 500 ] Training-Loss = 0.4331 Training-Accuracy = 0.5668804347515106 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 120 / 500 ] Training-Loss = 0.4340 Training-Accuracy = 0.5659553110599518 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 121 / 500 ] Training-Loss = 0.4361 Training-Accuracy = 0.5638671815395355 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 122 / 500 ] Training-Loss = 0.4387 Training-Accuracy = 0.5612829029560089 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 123 / 500 ] Training-Loss = 0.4412 Training-Accuracy = 0.5588257014751434 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 124 / 500 ] Training-Loss = 0.4430 Training-Accuracy = 0.5569933354854584 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 125 / 500 ] Training-Loss = 0.4439 Training-Accuracy = 0.556085616350174 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 126 / 500 ] Training-Loss = 0.4438 Training-Accuracy = 0.5561883747577667 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 127 / 500 ] Training-Loss = 0.4428 Training-Accuracy = 0.5572121441364288 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 128 / 500 ] Training-Loss = 0.4410 Training-Accuracy = 0.5589534640312195 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 129 / 500 ] Training-Loss = 0.4388 Training-Accuracy = 0.5611515641212463 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 130 / 500 ] Training-Loss = 0.4365 Training-Accuracy = 0.5635423362255096 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 131 / 500 ] Training-Loss = 0.4341 Training-Accuracy = 0.5658892393112183 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 132 / 500 ] Training-Loss = 0.4320 Training-Accuracy = 0.5680113732814789 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 133 / 500 ] Training-Loss = 0.4302 Training-Accuracy = 0.5697938799858093 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 134 / 500 ] Training-Loss = 0.4288 Training-Accuracy = 0.5711818933486938 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 135 / 500 ] Training-Loss = 0.4278 Training-Accuracy = 0.5721741616725922 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 136 / 500 ] Training-Loss = 0.4272 Training-Accuracy = 0.5728088915348053 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 137 / 500 ] Training-Loss = 0.4268 Training-Accuracy = 0.5731558203697205 Validation-Accuracy = 0.869281045751634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 138 / 500 ] Training-Loss = 0.4267 Training-Accuracy = 0.573297917842865 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 139 / 500 ] Training-Loss = 0.4267 Training-Accuracy = 0.5733185112476349 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 140 / 500 ] Training-Loss = 0.4267 Training-Accuracy = 0.5732945799827576 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 141 / 500 ] Training-Loss = 0.4267 Training-Accuracy = 0.5732890367507935 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 142 / 500 ] Training-Loss = 0.4267 Training-Accuracy = 0.5733481645584106 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 143 / 500 ] Training-Loss = 0.4265 Training-Accuracy = 0.5735004246234894 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 144 / 500 ] Training-Loss = 0.4262 Training-Accuracy = 0.5737593173980713 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 145 / 500 ] Training-Loss = 0.4259 Training-Accuracy = 0.574124276638031 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 146 / 500 ] Training-Loss = 0.4254 Training-Accuracy = 0.574583113193512 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 147 / 500 ] Training-Loss = 0.4249 Training-Accuracy = 0.5751166343688965 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 148 / 500 ] Training-Loss = 0.4243 Training-Accuracy = 0.5757004022598267 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 149 / 500 ] Training-Loss = 0.4237 Training-Accuracy = 0.5763091444969177 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 150 / 500 ] Training-Loss = 0.4231 Training-Accuracy = 0.5769197046756744 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 151 / 500 ] Training-Loss = 0.4225 Training-Accuracy = 0.5775102376937866 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 152 / 500 ] Training-Loss = 0.4219 Training-Accuracy = 0.5780645608901978 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 153 / 500 ] Training-Loss = 0.4214 Training-Accuracy = 0.5785724818706512 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 154 / 500 ] Training-Loss = 0.4210 Training-Accuracy = 0.579031229019165 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 155 / 500 ] Training-Loss = 0.4206 Training-Accuracy = 0.5794424414634705 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 156 / 500 ] Training-Loss = 0.4202 Training-Accuracy = 0.579812228679657 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 157 / 500 ] Training-Loss = 0.4199 Training-Accuracy = 0.5801498591899872 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 158 / 500 ] Training-Loss = 0.4195 Training-Accuracy = 0.5804681777954102 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 159 / 500 ] Training-Loss = 0.4192 Training-Accuracy = 0.5807783901691437 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 160 / 500 ] Training-Loss = 0.4189 Training-Accuracy = 0.5810897648334503 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 161 / 500 ] Training-Loss = 0.4186 Training-Accuracy = 0.5814116895198822 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 162 / 500 ] Training-Loss = 0.4182 Training-Accuracy = 0.5817507207393646 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 163 / 500 ] Training-Loss = 0.4179 Training-Accuracy = 0.5821093916893005 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 164 / 500 ] Training-Loss = 0.4175 Training-Accuracy = 0.582487940788269 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 165 / 500 ] Training-Loss = 0.4171 Training-Accuracy = 0.5828835666179657 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 166 / 500 ] Training-Loss = 0.4167 Training-Accuracy = 0.5832890570163727 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 167 / 500 ] Training-Loss = 0.4163 Training-Accuracy = 0.5836999714374542 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 168 / 500 ] Training-Loss = 0.4159 Training-Accuracy = 0.5841134190559387 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 169 / 500 ] Training-Loss = 0.4155 Training-Accuracy = 0.5845243334770203 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 170 / 500 ] Training-Loss = 0.4151 Training-Accuracy = 0.5849309265613556 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 171 / 500 ] Training-Loss = 0.4147 Training-Accuracy = 0.585331529378891 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 172 / 500 ] Training-Loss = 0.4143 Training-Accuracy = 0.5857254862785339 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 173 / 500 ] Training-Loss = 0.4139 Training-Accuracy = 0.5861139297485352 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 174 / 500 ] Training-Loss = 0.4135 Training-Accuracy = 0.5864981710910797 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 175 / 500 ] Training-Loss = 0.4131 Training-Accuracy = 0.5868799090385437 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 176 / 500 ] Training-Loss = 0.4127 Training-Accuracy = 0.5872609317302704 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 177 / 500 ] Training-Loss = 0.4124 Training-Accuracy = 0.5876436829566956 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 178 / 500 ] Training-Loss = 0.4120 Training-Accuracy = 0.5880293548107147 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 179 / 500 ] Training-Loss = 0.4116 Training-Accuracy = 0.5884189009666443 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 180 / 500 ] Training-Loss = 0.4112 Training-Accuracy = 0.5888121128082275 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 181 / 500 ] Training-Loss = 0.4108 Training-Accuracy = 0.5892108678817749 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 182 / 500 ] Training-Loss = 0.4104 Training-Accuracy = 0.5896144807338715 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 183 / 500 ] Training-Loss = 0.4100 Training-Accuracy = 0.5900224447250366 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 184 / 500 ] Training-Loss = 0.4096 Training-Accuracy = 0.5904335081577301 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 185 / 500 ] Training-Loss = 0.4092 Training-Accuracy = 0.5908468067646027 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 186 / 500 ] Training-Loss = 0.4087 Training-Accuracy = 0.5912620723247528 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 187 / 500 ] Training-Loss = 0.4083 Training-Accuracy = 0.5916771590709686 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 188 / 500 ] Training-Loss = 0.4079 Training-Accuracy = 0.5920941829681396 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 189 / 500 ] Training-Loss = 0.4075 Training-Accuracy = 0.5925108790397644 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 190 / 500 ] Training-Loss = 0.4071 Training-Accuracy = 0.5929287672042847 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 191 / 500 ] Training-Loss = 0.4067 Training-Accuracy = 0.5933473110198975 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 192 / 500 ] Training-Loss = 0.4062 Training-Accuracy = 0.5937677919864655 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 193 / 500 ] Training-Loss = 0.4058 Training-Accuracy = 0.5941899418830872 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 194 / 500 ] Training-Loss = 0.4054 Training-Accuracy = 0.5946148633956909 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 195 / 500 ] Training-Loss = 0.4050 Training-Accuracy = 0.5950415730476379 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 196 / 500 ] Training-Loss = 0.4045 Training-Accuracy = 0.595471203327179 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 197 / 500 ] Training-Loss = 0.4041 Training-Accuracy = 0.5959039628505707 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 198 / 500 ] Training-Loss = 0.4037 Training-Accuracy = 0.5963402986526489 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 199 / 500 ] Training-Loss = 0.4032 Training-Accuracy = 0.5967793166637421 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 200 / 500 ] Training-Loss = 0.4028 Training-Accuracy = 0.5972212255001068 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 201 / 500 ] Training-Loss = 0.4023 Training-Accuracy = 0.5976637303829193 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 202 / 500 ] Training-Loss = 0.4019 Training-Accuracy = 0.5981094241142273 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 203 / 500 ] Training-Loss = 0.4014 Training-Accuracy = 0.5985580682754517 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 204 / 500 ] Training-Loss = 0.4010 Training-Accuracy = 0.5990098714828491 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 205 / 500 ] Training-Loss = 0.4005 Training-Accuracy = 0.5994643568992615 Validation-Accuracy = 0.869281045751634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 206 / 500 ] Training-Loss = 0.4001 Training-Accuracy = 0.5999224185943604 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 207 / 500 ] Training-Loss = 0.3996 Training-Accuracy = 0.6003841459751129 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 208 / 500 ] Training-Loss = 0.3992 Training-Accuracy = 0.6008488833904266 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 209 / 500 ] Training-Loss = 0.3987 Training-Accuracy = 0.6013143956661224 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 210 / 500 ] Training-Loss = 0.3982 Training-Accuracy = 0.6017818748950958 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 211 / 500 ] Training-Loss = 0.3977 Training-Accuracy = 0.6022524237632751 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 212 / 500 ] Training-Loss = 0.3973 Training-Accuracy = 0.6027269065380096 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 213 / 500 ] Training-Loss = 0.3968 Training-Accuracy = 0.6032041907310486 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 214 / 500 ] Training-Loss = 0.3963 Training-Accuracy = 0.6036839485168457 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 215 / 500 ] Training-Loss = 0.3958 Training-Accuracy = 0.604167103767395 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 216 / 500 ] Training-Loss = 0.3953 Training-Accuracy = 0.6046532094478607 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 217 / 500 ] Training-Loss = 0.3949 Training-Accuracy = 0.6051421165466309 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 218 / 500 ] Training-Loss = 0.3944 Training-Accuracy = 0.6056346893310547 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 219 / 500 ] Training-Loss = 0.3939 Training-Accuracy = 0.6061310470104218 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 220 / 500 ] Training-Loss = 0.3934 Training-Accuracy = 0.6066334247589111 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 221 / 500 ] Training-Loss = 0.3929 Training-Accuracy = 0.6071367561817169 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 222 / 500 ] Training-Loss = 0.3924 Training-Accuracy = 0.607643187046051 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 223 / 500 ] Training-Loss = 0.3918 Training-Accuracy = 0.6081511080265045 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 224 / 500 ] Training-Loss = 0.3913 Training-Accuracy = 0.6086599826812744 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 225 / 500 ] Training-Loss = 0.3908 Training-Accuracy = 0.6091714203357697 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 226 / 500 ] Training-Loss = 0.3903 Training-Accuracy = 0.6096862256526947 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 227 / 500 ] Training-Loss = 0.3898 Training-Accuracy = 0.6102052628993988 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 228 / 500 ] Training-Loss = 0.3893 Training-Accuracy = 0.6107283234596252 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 229 / 500 ] Training-Loss = 0.3887 Training-Accuracy = 0.6112538576126099 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 230 / 500 ] Training-Loss = 0.3882 Training-Accuracy = 0.6117852628231049 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 231 / 500 ] Training-Loss = 0.3877 Training-Accuracy = 0.6123197972774506 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 232 / 500 ] Training-Loss = 0.3871 Training-Accuracy = 0.6128586828708649 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 233 / 500 ] Training-Loss = 0.3866 Training-Accuracy = 0.6134012341499329 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 234 / 500 ] Training-Loss = 0.3861 Training-Accuracy = 0.6139483749866486 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 235 / 500 ] Training-Loss = 0.3855 Training-Accuracy = 0.6144971251487732 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 236 / 500 ] Training-Loss = 0.3850 Training-Accuracy = 0.6150485277175903 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 237 / 500 ] Training-Loss = 0.3844 Training-Accuracy = 0.6156024634838104 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 238 / 500 ] Training-Loss = 0.3838 Training-Accuracy = 0.6161591112613678 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 239 / 500 ] Training-Loss = 0.3833 Training-Accuracy = 0.6167188286781311 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 240 / 500 ] Training-Loss = 0.3827 Training-Accuracy = 0.6172796487808228 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 241 / 500 ] Training-Loss = 0.3822 Training-Accuracy = 0.6178443729877472 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 242 / 500 ] Training-Loss = 0.3816 Training-Accuracy = 0.6184123456478119 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 243 / 500 ] Training-Loss = 0.3810 Training-Accuracy = 0.6189827919006348 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 244 / 500 ] Training-Loss = 0.3804 Training-Accuracy = 0.6195564568042755 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 245 / 500 ] Training-Loss = 0.3799 Training-Accuracy = 0.6201359331607819 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 246 / 500 ] Training-Loss = 0.3793 Training-Accuracy = 0.6207200288772583 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 247 / 500 ] Training-Loss = 0.3787 Training-Accuracy = 0.6213052868843079 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 248 / 500 ] Training-Loss = 0.3781 Training-Accuracy = 0.6218911707401276 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 249 / 500 ] Training-Loss = 0.3775 Training-Accuracy = 0.6224835515022278 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 250 / 500 ] Training-Loss = 0.3769 Training-Accuracy = 0.6230806112289429 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 251 / 500 ] Training-Loss = 0.3763 Training-Accuracy = 0.6236821115016937 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 252 / 500 ] Training-Loss = 0.3757 Training-Accuracy = 0.6242877840995789 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 253 / 500 ] Training-Loss = 0.3751 Training-Accuracy = 0.6248974800109863 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 254 / 500 ] Training-Loss = 0.3745 Training-Accuracy = 0.6255128681659698 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 255 / 500 ] Training-Loss = 0.3739 Training-Accuracy = 0.6261326670646667 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 256 / 500 ] Training-Loss = 0.3732 Training-Accuracy = 0.6267572343349457 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 257 / 500 ] Training-Loss = 0.3726 Training-Accuracy = 0.6273860335350037 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 258 / 500 ] Training-Loss = 0.3720 Training-Accuracy = 0.6280181407928467 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 259 / 500 ] Training-Loss = 0.3713 Training-Accuracy = 0.6286549270153046 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 260 / 500 ] Training-Loss = 0.3707 Training-Accuracy = 0.6292968094348907 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 261 / 500 ] Training-Loss = 0.3701 Training-Accuracy = 0.6299423575401306 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 262 / 500 ] Training-Loss = 0.3694 Training-Accuracy = 0.6305945813655853 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 263 / 500 ] Training-Loss = 0.3687 Training-Accuracy = 0.6312501430511475 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 264 / 500 ] Training-Loss = 0.3681 Training-Accuracy = 0.6319125592708588 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 265 / 500 ] Training-Loss = 0.3674 Training-Accuracy = 0.6325764954090118 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 266 / 500 ] Training-Loss = 0.3668 Training-Accuracy = 0.6332435607910156 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 267 / 500 ] Training-Loss = 0.3661 Training-Accuracy = 0.633913516998291 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 268 / 500 ] Training-Loss = 0.3654 Training-Accuracy = 0.6345869600772858 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 269 / 500 ] Training-Loss = 0.3647 Training-Accuracy = 0.6352654993534088 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 270 / 500 ] Training-Loss = 0.3641 Training-Accuracy = 0.6359474360942841 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 271 / 500 ] Training-Loss = 0.3634 Training-Accuracy = 0.6366389691829681 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 272 / 500 ] Training-Loss = 0.3627 Training-Accuracy = 0.637334018945694 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 273 / 500 ] Training-Loss = 0.3620 Training-Accuracy = 0.6380351483821869 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 274 / 500 ] Training-Loss = 0.3613 Training-Accuracy = 0.6387450695037842 Validation-Accuracy = 0.869281045751634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 275 / 500 ] Training-Loss = 0.3605 Training-Accuracy = 0.6394682824611664 Validation-Accuracy = 0.869281045751634\n",
      "Epoch [ 276 / 500 ] Training-Loss = 0.3598 Training-Accuracy = 0.6401938796043396 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 277 / 500 ] Training-Loss = 0.3591 Training-Accuracy = 0.6409088373184204 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 278 / 500 ] Training-Loss = 0.3584 Training-Accuracy = 0.6416147947311401 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 279 / 500 ] Training-Loss = 0.3577 Training-Accuracy = 0.6423209011554718 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 280 / 500 ] Training-Loss = 0.3570 Training-Accuracy = 0.6430259048938751 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 281 / 500 ] Training-Loss = 0.3563 Training-Accuracy = 0.6437257826328278 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 282 / 500 ] Training-Loss = 0.3556 Training-Accuracy = 0.6444241404533386 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 283 / 500 ] Training-Loss = 0.3549 Training-Accuracy = 0.645120233297348 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 284 / 500 ] Training-Loss = 0.3542 Training-Accuracy = 0.6458079814910889 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 285 / 500 ] Training-Loss = 0.3535 Training-Accuracy = 0.6464932858943939 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 286 / 500 ] Training-Loss = 0.3528 Training-Accuracy = 0.6471677124500275 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 287 / 500 ] Training-Loss = 0.3522 Training-Accuracy = 0.6478359699249268 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 288 / 500 ] Training-Loss = 0.3515 Training-Accuracy = 0.6484960913658142 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 289 / 500 ] Training-Loss = 0.3509 Training-Accuracy = 0.6491446197032928 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 290 / 500 ] Training-Loss = 0.3502 Training-Accuracy = 0.6497740745544434 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 291 / 500 ] Training-Loss = 0.3496 Training-Accuracy = 0.6503943502902985 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 292 / 500 ] Training-Loss = 0.3490 Training-Accuracy = 0.6510076820850372 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 293 / 500 ] Training-Loss = 0.3484 Training-Accuracy = 0.6516168713569641 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 294 / 500 ] Training-Loss = 0.3478 Training-Accuracy = 0.652219831943512 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 295 / 500 ] Training-Loss = 0.3472 Training-Accuracy = 0.65281081199646 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 296 / 500 ] Training-Loss = 0.3466 Training-Accuracy = 0.653395265340805 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 297 / 500 ] Training-Loss = 0.3460 Training-Accuracy = 0.6539732217788696 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 298 / 500 ] Training-Loss = 0.3455 Training-Accuracy = 0.6545437574386597 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 299 / 500 ] Training-Loss = 0.3449 Training-Accuracy = 0.6551087498664856 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 300 / 500 ] Training-Loss = 0.3443 Training-Accuracy = 0.6556677222251892 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 301 / 500 ] Training-Loss = 0.3438 Training-Accuracy = 0.6562187969684601 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 302 / 500 ] Training-Loss = 0.3432 Training-Accuracy = 0.6567653119564056 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 303 / 500 ] Training-Loss = 0.3427 Training-Accuracy = 0.6573090553283691 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 304 / 500 ] Training-Loss = 0.3421 Training-Accuracy = 0.6578504741191864 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 305 / 500 ] Training-Loss = 0.3416 Training-Accuracy = 0.6583935022354126 Validation-Accuracy = 0.8856209150326797\n",
      "Epoch [ 306 / 500 ] Training-Loss = 0.3411 Training-Accuracy = 0.658936083316803 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 307 / 500 ] Training-Loss = 0.3405 Training-Accuracy = 0.659470945596695 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 308 / 500 ] Training-Loss = 0.3400 Training-Accuracy = 0.6599947512149811 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 309 / 500 ] Training-Loss = 0.3395 Training-Accuracy = 0.6605042517185211 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 310 / 500 ] Training-Loss = 0.3390 Training-Accuracy = 0.6610074043273926 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 311 / 500 ] Training-Loss = 0.3385 Training-Accuracy = 0.6615058779716492 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 312 / 500 ] Training-Loss = 0.3380 Training-Accuracy = 0.661998063325882 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 313 / 500 ] Training-Loss = 0.3375 Training-Accuracy = 0.6624803245067596 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 314 / 500 ] Training-Loss = 0.3370 Training-Accuracy = 0.6629588305950165 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 315 / 500 ] Training-Loss = 0.3366 Training-Accuracy = 0.6634381413459778 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 316 / 500 ] Training-Loss = 0.3361 Training-Accuracy = 0.6639131605625153 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 317 / 500 ] Training-Loss = 0.3356 Training-Accuracy = 0.6643833518028259 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 318 / 500 ] Training-Loss = 0.3351 Training-Accuracy = 0.6648502349853516 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 319 / 500 ] Training-Loss = 0.3347 Training-Accuracy = 0.6653105318546295 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 320 / 500 ] Training-Loss = 0.3342 Training-Accuracy = 0.6657638847827911 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 321 / 500 ] Training-Loss = 0.3338 Training-Accuracy = 0.6662060916423798 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 322 / 500 ] Training-Loss = 0.3334 Training-Accuracy = 0.6666413843631744 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 323 / 500 ] Training-Loss = 0.3329 Training-Accuracy = 0.6670742630958557 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 324 / 500 ] Training-Loss = 0.3325 Training-Accuracy = 0.6675090789794922 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 325 / 500 ] Training-Loss = 0.3321 Training-Accuracy = 0.6679445207118988 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 326 / 500 ] Training-Loss = 0.3316 Training-Accuracy = 0.6683832705020905 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 327 / 500 ] Training-Loss = 0.3312 Training-Accuracy = 0.6688205003738403 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 328 / 500 ] Training-Loss = 0.3307 Training-Accuracy = 0.669259786605835 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 329 / 500 ] Training-Loss = 0.3303 Training-Accuracy = 0.6697004735469818 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 330 / 500 ] Training-Loss = 0.3299 Training-Accuracy = 0.670140415430069 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 331 / 500 ] Training-Loss = 0.3294 Training-Accuracy = 0.670578807592392 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 332 / 500 ] Training-Loss = 0.3290 Training-Accuracy = 0.6710165143013 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 333 / 500 ] Training-Loss = 0.3285 Training-Accuracy = 0.671454668045044 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 334 / 500 ] Training-Loss = 0.3281 Training-Accuracy = 0.6718967258930206 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 335 / 500 ] Training-Loss = 0.3277 Training-Accuracy = 0.672343522310257 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 336 / 500 ] Training-Loss = 0.3272 Training-Accuracy = 0.6727906465530396 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 337 / 500 ] Training-Loss = 0.3268 Training-Accuracy = 0.6732418835163116 Validation-Accuracy = 0.8954248366013072\n",
      "Epoch [ 338 / 500 ] Training-Loss = 0.3263 Training-Accuracy = 0.6736931204795837 Validation-Accuracy = 0.8954248366013072\n",
      "Epoch [ 339 / 500 ] Training-Loss = 0.3259 Training-Accuracy = 0.6741447448730469 Validation-Accuracy = 0.8954248366013072\n",
      "Epoch [ 340 / 500 ] Training-Loss = 0.3254 Training-Accuracy = 0.6745975315570831 Validation-Accuracy = 0.8954248366013072\n",
      "Epoch [ 341 / 500 ] Training-Loss = 0.3250 Training-Accuracy = 0.6750495731830597 Validation-Accuracy = 0.8954248366013072\n",
      "Epoch [ 342 / 500 ] Training-Loss = 0.3245 Training-Accuracy = 0.6755030751228333 Validation-Accuracy = 0.8954248366013072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 343 / 500 ] Training-Loss = 0.3240 Training-Accuracy = 0.6759584844112396 Validation-Accuracy = 0.8954248366013072\n",
      "Epoch [ 344 / 500 ] Training-Loss = 0.3236 Training-Accuracy = 0.676418274641037 Validation-Accuracy = 0.8954248366013072\n",
      "Epoch [ 345 / 500 ] Training-Loss = 0.3231 Training-Accuracy = 0.6768836379051208 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 346 / 500 ] Training-Loss = 0.3226 Training-Accuracy = 0.6773508787155151 Validation-Accuracy = 0.8954248366013072\n",
      "Epoch [ 347 / 500 ] Training-Loss = 0.3222 Training-Accuracy = 0.6778181195259094 Validation-Accuracy = 0.8986928104575164\n",
      "Epoch [ 348 / 500 ] Training-Loss = 0.3217 Training-Accuracy = 0.6782884895801544 Validation-Accuracy = 0.8986928104575164\n",
      "Epoch [ 349 / 500 ] Training-Loss = 0.3212 Training-Accuracy = 0.6787594556808472 Validation-Accuracy = 0.8986928104575164\n",
      "Epoch [ 350 / 500 ] Training-Loss = 0.3208 Training-Accuracy = 0.6792353689670563 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 351 / 500 ] Training-Loss = 0.3203 Training-Accuracy = 0.6797155737876892 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 352 / 500 ] Training-Loss = 0.3198 Training-Accuracy = 0.6801961362361908 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 353 / 500 ] Training-Loss = 0.3193 Training-Accuracy = 0.6806816756725311 Validation-Accuracy = 0.8921568627450981\n",
      "Epoch [ 354 / 500 ] Training-Loss = 0.3188 Training-Accuracy = 0.6811742782592773 Validation-Accuracy = 0.8954248366013072\n",
      "Epoch [ 355 / 500 ] Training-Loss = 0.3183 Training-Accuracy = 0.6816760003566742 Validation-Accuracy = 0.8986928104575164\n",
      "Epoch [ 356 / 500 ] Training-Loss = 0.3178 Training-Accuracy = 0.6821790337562561 Validation-Accuracy = 0.9019607843137255\n",
      "Epoch [ 357 / 500 ] Training-Loss = 0.3173 Training-Accuracy = 0.6826862096786499 Validation-Accuracy = 0.9019607843137255\n",
      "Epoch [ 358 / 500 ] Training-Loss = 0.3168 Training-Accuracy = 0.6831948459148407 Validation-Accuracy = 0.9019607843137255\n",
      "Epoch [ 359 / 500 ] Training-Loss = 0.3163 Training-Accuracy = 0.683706134557724 Validation-Accuracy = 0.9019607843137255\n",
      "Epoch [ 360 / 500 ] Training-Loss = 0.3158 Training-Accuracy = 0.6842151880264282 Validation-Accuracy = 0.9019607843137255\n",
      "Epoch [ 361 / 500 ] Training-Loss = 0.3153 Training-Accuracy = 0.6847286820411682 Validation-Accuracy = 0.9019607843137255\n",
      "Epoch [ 362 / 500 ] Training-Loss = 0.3147 Training-Accuracy = 0.6852521896362305 Validation-Accuracy = 0.9019607843137255\n",
      "Epoch [ 363 / 500 ] Training-Loss = 0.3142 Training-Accuracy = 0.6857832074165344 Validation-Accuracy = 0.9019607843137255\n",
      "Epoch [ 364 / 500 ] Training-Loss = 0.3137 Training-Accuracy = 0.6863205134868622 Validation-Accuracy = 0.9019607843137255\n",
      "Epoch [ 365 / 500 ] Training-Loss = 0.3131 Training-Accuracy = 0.6868664026260376 Validation-Accuracy = 0.9052287581699346\n",
      "Epoch [ 366 / 500 ] Training-Loss = 0.3126 Training-Accuracy = 0.6874120831489563 Validation-Accuracy = 0.9052287581699346\n",
      "Epoch [ 367 / 500 ] Training-Loss = 0.3120 Training-Accuracy = 0.6879581212997437 Validation-Accuracy = 0.9052287581699346\n",
      "Epoch [ 368 / 500 ] Training-Loss = 0.3115 Training-Accuracy = 0.6885150969028473 Validation-Accuracy = 0.9052287581699346\n",
      "Epoch [ 369 / 500 ] Training-Loss = 0.3109 Training-Accuracy = 0.6890683472156525 Validation-Accuracy = 0.9084967320261438\n",
      "Epoch [ 370 / 500 ] Training-Loss = 0.3104 Training-Accuracy = 0.6896280944347382 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 371 / 500 ] Training-Loss = 0.3098 Training-Accuracy = 0.6902011334896088 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 372 / 500 ] Training-Loss = 0.3092 Training-Accuracy = 0.6907682418823242 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 373 / 500 ] Training-Loss = 0.3087 Training-Accuracy = 0.6913301050662994 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 374 / 500 ] Training-Loss = 0.3081 Training-Accuracy = 0.6919025480747223 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 375 / 500 ] Training-Loss = 0.3075 Training-Accuracy = 0.6924693286418915 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 376 / 500 ] Training-Loss = 0.3070 Training-Accuracy = 0.6930382251739502 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 377 / 500 ] Training-Loss = 0.3064 Training-Accuracy = 0.6936009526252747 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 378 / 500 ] Training-Loss = 0.3058 Training-Accuracy = 0.6941657066345215 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 379 / 500 ] Training-Loss = 0.3053 Training-Accuracy = 0.6947353184223175 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 380 / 500 ] Training-Loss = 0.3047 Training-Accuracy = 0.6953024864196777 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 381 / 500 ] Training-Loss = 0.3041 Training-Accuracy = 0.6958677470684052 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 382 / 500 ] Training-Loss = 0.3036 Training-Accuracy = 0.6964361369609833 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 383 / 500 ] Training-Loss = 0.3030 Training-Accuracy = 0.697000652551651 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 384 / 500 ] Training-Loss = 0.3024 Training-Accuracy = 0.6975650489330292 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 385 / 500 ] Training-Loss = 0.3019 Training-Accuracy = 0.6981321275234222 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 386 / 500 ] Training-Loss = 0.3013 Training-Accuracy = 0.6986954212188721 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 387 / 500 ] Training-Loss = 0.3007 Training-Accuracy = 0.6992687582969666 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 388 / 500 ] Training-Loss = 0.3002 Training-Accuracy = 0.6998460590839386 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 389 / 500 ] Training-Loss = 0.2996 Training-Accuracy = 0.7004238069057465 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 390 / 500 ] Training-Loss = 0.2990 Training-Accuracy = 0.700998842716217 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 391 / 500 ] Training-Loss = 0.2984 Training-Accuracy = 0.7015511989593506 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 392 / 500 ] Training-Loss = 0.2979 Training-Accuracy = 0.7021032571792603 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 393 / 500 ] Training-Loss = 0.2973 Training-Accuracy = 0.702662855386734 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 394 / 500 ] Training-Loss = 0.2968 Training-Accuracy = 0.7031981945037842 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 395 / 500 ] Training-Loss = 0.2962 Training-Accuracy = 0.7037957906723022 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 396 / 500 ] Training-Loss = 0.2957 Training-Accuracy = 0.704332023859024 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 397 / 500 ] Training-Loss = 0.2951 Training-Accuracy = 0.7049337029457092 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 398 / 500 ] Training-Loss = 0.2945 Training-Accuracy = 0.705464094877243 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 399 / 500 ] Training-Loss = 0.2939 Training-Accuracy = 0.7060570120811462 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 400 / 500 ] Training-Loss = 0.2934 Training-Accuracy = 0.7066320478916168 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 401 / 500 ] Training-Loss = 0.2928 Training-Accuracy = 0.7071972489356995 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 402 / 500 ] Training-Loss = 0.2922 Training-Accuracy = 0.7077955305576324 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 403 / 500 ] Training-Loss = 0.2916 Training-Accuracy = 0.7083500623703003 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 404 / 500 ] Training-Loss = 0.2910 Training-Accuracy = 0.7089713215827942 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 405 / 500 ] Training-Loss = 0.2905 Training-Accuracy = 0.7095274031162262 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 406 / 500 ] Training-Loss = 0.2899 Training-Accuracy = 0.7101193368434906 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 407 / 500 ] Training-Loss = 0.2893 Training-Accuracy = 0.7106897234916687 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 408 / 500 ] Training-Loss = 0.2887 Training-Accuracy = 0.7112791240215302 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 409 / 500 ] Training-Loss = 0.2881 Training-Accuracy = 0.7118775844573975 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 410 / 500 ] Training-Loss = 0.2876 Training-Accuracy = 0.7124448120594025 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 411 / 500 ] Training-Loss = 0.2870 Training-Accuracy = 0.7130479514598846 Validation-Accuracy = 0.9150326797385621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 412 / 500 ] Training-Loss = 0.2864 Training-Accuracy = 0.7136164605617523 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 413 / 500 ] Training-Loss = 0.2858 Training-Accuracy = 0.7142221629619598 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 414 / 500 ] Training-Loss = 0.2852 Training-Accuracy = 0.7147887051105499 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 415 / 500 ] Training-Loss = 0.2846 Training-Accuracy = 0.7153941988945007 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 416 / 500 ] Training-Loss = 0.2840 Training-Accuracy = 0.715965986251831 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 417 / 500 ] Training-Loss = 0.2834 Training-Accuracy = 0.7165780067443848 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 418 / 500 ] Training-Loss = 0.2828 Training-Accuracy = 0.7171552777290344 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 419 / 500 ] Training-Loss = 0.2822 Training-Accuracy = 0.7177522778511047 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 420 / 500 ] Training-Loss = 0.2817 Training-Accuracy = 0.7183395624160767 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 421 / 500 ] Training-Loss = 0.2811 Training-Accuracy = 0.7189191579818726 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 422 / 500 ] Training-Loss = 0.2805 Training-Accuracy = 0.7195244431495667 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 423 / 500 ] Training-Loss = 0.2799 Training-Accuracy = 0.7201213538646698 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 424 / 500 ] Training-Loss = 0.2793 Training-Accuracy = 0.720724493265152 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 425 / 500 ] Training-Loss = 0.2787 Training-Accuracy = 0.7213097214698792 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 426 / 500 ] Training-Loss = 0.2781 Training-Accuracy = 0.721877247095108 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 427 / 500 ] Training-Loss = 0.2776 Training-Accuracy = 0.7224493026733398 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 428 / 500 ] Training-Loss = 0.2770 Training-Accuracy = 0.7230036556720734 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 429 / 500 ] Training-Loss = 0.2764 Training-Accuracy = 0.723561018705368 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 430 / 500 ] Training-Loss = 0.2759 Training-Accuracy = 0.7241233289241791 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 431 / 500 ] Training-Loss = 0.2753 Training-Accuracy = 0.7246830463409424 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 432 / 500 ] Training-Loss = 0.2748 Training-Accuracy = 0.725241094827652 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 433 / 500 ] Training-Loss = 0.2742 Training-Accuracy = 0.7257950901985168 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 434 / 500 ] Training-Loss = 0.2737 Training-Accuracy = 0.7263439297676086 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 435 / 500 ] Training-Loss = 0.2731 Training-Accuracy = 0.7268920540809631 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 436 / 500 ] Training-Loss = 0.2726 Training-Accuracy = 0.7274367213249207 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 437 / 500 ] Training-Loss = 0.2720 Training-Accuracy = 0.7279899716377258 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 438 / 500 ] Training-Loss = 0.2715 Training-Accuracy = 0.7285390496253967 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 439 / 500 ] Training-Loss = 0.2709 Training-Accuracy = 0.7290996611118317 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 440 / 500 ] Training-Loss = 0.2703 Training-Accuracy = 0.7296639978885651 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 441 / 500 ] Training-Loss = 0.2698 Training-Accuracy = 0.7302291393280029 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 442 / 500 ] Training-Loss = 0.2692 Training-Accuracy = 0.7307715713977814 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 443 / 500 ] Training-Loss = 0.2687 Training-Accuracy = 0.7313413918018341 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 444 / 500 ] Training-Loss = 0.2681 Training-Accuracy = 0.7319315671920776 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 445 / 500 ] Training-Loss = 0.2675 Training-Accuracy = 0.73247891664505 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 446 / 500 ] Training-Loss = 0.2670 Training-Accuracy = 0.7330027520656586 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 447 / 500 ] Training-Loss = 0.2664 Training-Accuracy = 0.7335662841796875 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 448 / 500 ] Training-Loss = 0.2659 Training-Accuracy = 0.7340945303440094 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 449 / 500 ] Training-Loss = 0.2654 Training-Accuracy = 0.7345826327800751 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 450 / 500 ] Training-Loss = 0.2649 Training-Accuracy = 0.7351258397102356 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 451 / 500 ] Training-Loss = 0.2643 Training-Accuracy = 0.7356854677200317 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 452 / 500 ] Training-Loss = 0.2639 Training-Accuracy = 0.736127495765686 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 453 / 500 ] Training-Loss = 0.2634 Training-Accuracy = 0.7366096079349518 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 454 / 500 ] Training-Loss = 0.2628 Training-Accuracy = 0.7371518611907959 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 455 / 500 ] Training-Loss = 0.2623 Training-Accuracy = 0.7376583814620972 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 456 / 500 ] Training-Loss = 0.2619 Training-Accuracy = 0.7380715310573578 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 457 / 500 ] Training-Loss = 0.2615 Training-Accuracy = 0.7384671568870544 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 458 / 500 ] Training-Loss = 0.2610 Training-Accuracy = 0.7390080690383911 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 459 / 500 ] Training-Loss = 0.2605 Training-Accuracy = 0.7395330369472504 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 460 / 500 ] Training-Loss = 0.2600 Training-Accuracy = 0.7399857640266418 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 461 / 500 ] Training-Loss = 0.2596 Training-Accuracy = 0.7403903007507324 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 462 / 500 ] Training-Loss = 0.2593 Training-Accuracy = 0.7407213747501373 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 463 / 500 ] Training-Loss = 0.2588 Training-Accuracy = 0.7411902546882629 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 464 / 500 ] Training-Loss = 0.2583 Training-Accuracy = 0.7417460680007935 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 465 / 500 ] Training-Loss = 0.2578 Training-Accuracy = 0.7422235310077667 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 466 / 500 ] Training-Loss = 0.2575 Training-Accuracy = 0.7425492405891418 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 467 / 500 ] Training-Loss = 0.2571 Training-Accuracy = 0.7428884208202362 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 468 / 500 ] Training-Loss = 0.2566 Training-Accuracy = 0.7434246242046356 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 469 / 500 ] Training-Loss = 0.2561 Training-Accuracy = 0.7439104318618774 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 470 / 500 ] Training-Loss = 0.2558 Training-Accuracy = 0.7441874444484711 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 471 / 500 ] Training-Loss = 0.2555 Training-Accuracy = 0.7444966435432434 Validation-Accuracy = 0.9084967320261438\n",
      "Epoch [ 472 / 500 ] Training-Loss = 0.2551 Training-Accuracy = 0.7449255883693695 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 473 / 500 ] Training-Loss = 0.2545 Training-Accuracy = 0.7454853653907776 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 474 / 500 ] Training-Loss = 0.2542 Training-Accuracy = 0.7457945346832275 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 475 / 500 ] Training-Loss = 0.2541 Training-Accuracy = 0.7459339797496796 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 476 / 500 ] Training-Loss = 0.2536 Training-Accuracy = 0.7463577389717102 Validation-Accuracy = 0.9150326797385621\n",
      "Epoch [ 477 / 500 ] Training-Loss = 0.2531 Training-Accuracy = 0.7468580007553101 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 478 / 500 ] Training-Loss = 0.2527 Training-Accuracy = 0.7472600042819977 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 479 / 500 ] Training-Loss = 0.2525 Training-Accuracy = 0.7474811971187592 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 480 / 500 ] Training-Loss = 0.2523 Training-Accuracy = 0.7476828992366791 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 481 / 500 ] Training-Loss = 0.2519 Training-Accuracy = 0.7481456995010376 Validation-Accuracy = 0.9117647058823529\n",
      "Epoch [ 482 / 500 ] Training-Loss = 0.2514 Training-Accuracy = 0.7485528886318207 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 483 / 500 ] Training-Loss = 0.2513 Training-Accuracy = 0.7487426400184631 Validation-Accuracy = 0.9117647058823529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 484 / 500 ] Training-Loss = 0.2511 Training-Accuracy = 0.7489468455314636 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 485 / 500 ] Training-Loss = 0.2507 Training-Accuracy = 0.74929079413414 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 486 / 500 ] Training-Loss = 0.2503 Training-Accuracy = 0.749735951423645 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 487 / 500 ] Training-Loss = 0.2499 Training-Accuracy = 0.750051885843277 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 488 / 500 ] Training-Loss = 0.2498 Training-Accuracy = 0.7502288669347763 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 489 / 500 ] Training-Loss = 0.2496 Training-Accuracy = 0.7504225224256516 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 490 / 500 ] Training-Loss = 0.2492 Training-Accuracy = 0.7507832050323486 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 491 / 500 ] Training-Loss = 0.2488 Training-Accuracy = 0.7511656433343887 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 492 / 500 ] Training-Loss = 0.2486 Training-Accuracy = 0.7514213472604752 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 493 / 500 ] Training-Loss = 0.2484 Training-Accuracy = 0.7515952438116074 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 494 / 500 ] Training-Loss = 0.2482 Training-Accuracy = 0.7518304288387299 Validation-Accuracy = 0.9215686274509803\n",
      "Epoch [ 495 / 500 ] Training-Loss = 0.2479 Training-Accuracy = 0.7521163821220398 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 496 / 500 ] Training-Loss = 0.2475 Training-Accuracy = 0.7524603009223938 Validation-Accuracy = 0.9248366013071896\n",
      "Epoch [ 497 / 500 ] Training-Loss = 0.2472 Training-Accuracy = 0.7527542561292648 Validation-Accuracy = 0.9248366013071896\n",
      "Epoch [ 498 / 500 ] Training-Loss = 0.2470 Training-Accuracy = 0.7530096620321274 Validation-Accuracy = 0.9183006535947712\n",
      "Epoch [ 499 / 500 ] Training-Loss = 0.2468 Training-Accuracy = 0.7532200366258621 Validation-Accuracy = 0.9248366013071896\n",
      "Epoch [ 500 / 500 ] Training-Loss = 0.2466 Training-Accuracy = 0.7534352838993073 Validation-Accuracy = 0.9183006535947712\n"
     ]
    }
   ],
   "source": [
    "val_acc_list = []\n",
    "training_acc_list = []\n",
    "model_list = []\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    predicted = model(x_train).to(device)    \n",
    "\n",
    "    loss = lossfn(predicted,y_train)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    val_acc = Validator(x_test, y_test.to(torch.int))\n",
    "    \n",
    "    print(f'Epoch [ {epoch+1} / {n_epochs} ] Training-Loss = {loss.item():.4f} Training-Accuracy = {1- loss.item():.4f} Validation-Accuracy = {val_acc:.4f}')\n",
    "    \n",
    "    training_acc_list.append(1-loss.item())\n",
    "    val_acc_list.append(val_acc)\n",
    "    model_list.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Training Accuracy =  0.7534352838993073\n",
      "Maximum Validation Accuracy =  0.9248366013071896\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum Training Accuracy = \", max(training_acc_list))\n",
    "print(\"Maximum Validation Accuracy = \",max(val_acc_list) )\n",
    "model = model_list[val_acc_list.index(max(val_acc_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Confusion Matrix for Train Data : \n",
      "\n",
      "         True Positive =  129            True Negetive =  66\n",
      "        False Positive =  32           False Negetive =  994\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Total Cases : 1221\n",
      "\n",
      "Accuracy  :  0.9197379197379197\n",
      "Precision :  0.8012422360248447\n",
      "Recall    :  0.6615384615384615\n",
      "F1 Score  :  0.7247191011235955\n",
      "\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "predicted = model(x_train).to(device)\n",
    "predicted = torch.max(predicted.data,1)[1]\n",
    "confusionMatrixPrint(predicted.to('cpu').numpy(),y_train.to('cpu').numpy(),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Confusion Matrix for Validation Data \n",
      "\n",
      "         True Positive =  25            True Negetive =  15\n",
      "        False Positive =  10           False Negetive =  256\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Total Cases : 306\n",
      "\n",
      "Accuracy  :  0.9183006535947712\n",
      "Precision :  0.7142857142857143\n",
      "Recall    :  0.625\n",
      "F1 Score  :  0.6666666666666666\n",
      "\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "predicted = model(x_test).to(device)\n",
    "predicted = torch.max(predicted.data,1)[1]\n",
    "confusionMatrixPrint(predicted.to('cpu').numpy(),y_test.to('cpu').numpy(),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_list.clear()\n",
    "training_acc_list.clear()\n",
    "model_list.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Nueral Network Based Classifier on Bag Words Technique\n",
    "\n",
    "## LSTM Based Network of :\n",
    "     - Input Layer : 18, 256\n",
    "     - LSTM Layer 1 : 256 , 256\n",
    "     - LSTM Layer 2 : 256 , 256\n",
    "     - LSTM Layer 3 : 256 , 256\n",
    "     - LSTM Layer 4 : 256 , 256\n",
    "     - LSTM Layer 5 : 256 , 256\n",
    "     - LSTM Layer 6 : 256 , 256\n",
    "     - LSTM Layer 7 : 256 , 256\n",
    "     - LSTM Layer 8 : 256 , 256\n",
    "     - LSTM Layer 9 : 256 , 256\n",
    "     - LSTM Layer 10 : 256 , 256\n",
    "     - LSTM Layer 11 : 256 , 256\n",
    "     - LSTM Layer 12 : 256 , 256\n",
    "     - LSTM Layer 13 : 256 , 256\n",
    "     - LSTM Layer 14 : 256 , 256\n",
    "     - LSTM Layer 15 : 256 , 256\n",
    "     - LSTM Layer 16 : 256 , 256\n",
    "     - Output Layer  : 256 , 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import warnings\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from filters import train_test_splitter, get_users_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "def get_Device():\n",
    "    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = get_Device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_users_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6533 words are used\n",
      "\n",
      "6533\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df.tweet_text)\n",
    "print(f\"{len(tokenizer.word_index)} words are used\\n\")\n",
    "\n",
    "counts = tokenizer.word_counts\n",
    "print(len(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_size=7000\n",
    "vocab_size = word_size\n",
    "tokenizer = Tokenizer(num_words=word_size)\n",
    "\n",
    "tokenizer.fit_on_texts(df.tweet_text)\n",
    "tokenized = tokenizer.texts_to_sequences(df.tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average words length of all tweets>> 13.114906832298137\n",
      "Maximum words length of a tweet_text >> 40\n",
      "Pad all sequences into size of 18\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(s) for s in tokenized]\n",
    "print(f\"Average words length of all tweets>> {np.mean(lengths)}\")\n",
    "print(f\"Maximum words length of a tweet_text >> {np.max(lengths)}\")\n",
    "\n",
    "sequence_size = 18\n",
    "print(f\"Pad all sequences into size of {sequence_size}\")\n",
    "\n",
    "padded = pad_sequences(tokenized,maxlen=sequence_size,padding='post',truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(padded, df.Annotation.values, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1288, 18), (322, 18))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1288,), (322,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 1, x_train.shape[1])\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, x_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[74, 75, 76, 77, 78, 65, 79, 80, 60, 81, 16, 72,  9, 10, 57,  0,\n",
       "         0,  0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.Tensor(x_train).to(device)\n",
    "y_train = torch.Tensor(y_train).to(device)\n",
    "x_test = torch.Tensor(x_test).to(device)\n",
    "y_test = torch.Tensor(y_test).to(device)\n",
    "y_train = y_train.to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 18\n",
    "output_size = 2\n",
    "hidden_size = 32\n",
    "num_layers = 4\n",
    "learning_rate = 0.0001\n",
    "n_epochs = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkClassifierModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(NeuralNetworkClassifierModel, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h0 = torch.zeros(self.num_layers, inputs.size(1), self.hidden_size).to(device) \n",
    "        c0 =  torch.zeros(self.num_layers, inputs.size(1), self.hidden_size).to(device) \n",
    "        \n",
    "        out, _ = self.lstm(inputs, (h0, c0))  \n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetworkClassifierModel(input_size = input_size,\n",
    "                                     hidden_size = hidden_size,\n",
    "                                     num_layers = num_layers,\n",
    "                                     output_size = output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetworkClassifierModel(\n",
       "  (lstm): LSTM(18, 32, num_layers=4)\n",
       "  (fc): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfn = torch.nn.CrossEntropyLoss()\n",
    "lossfn.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Validate(x_test, y_test):\n",
    "    predicted = model(x_test).to(device)\n",
    "    pred = torch.max(predicted.data,1)[1]\n",
    "    total_test = len(y_test)\n",
    "    correct_pred = 0\n",
    "    for i in range(total_test):\n",
    "        if y_test[i] == pred[i]:\n",
    "            correct_pred += 1\n",
    "    return correct_pred/total_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/512] Training-Loss = 0.8335 Train-Accuracy = 0.1665 Valid-Accuracy = 0.1491\n",
      "Epoch [2/512] Training-Loss = 0.8325 Train-Accuracy = 0.1675 Valid-Accuracy = 0.1491\n",
      "Epoch [3/512] Training-Loss = 0.8315 Train-Accuracy = 0.1685 Valid-Accuracy = 0.1491\n",
      "Epoch [4/512] Training-Loss = 0.8306 Train-Accuracy = 0.1694 Valid-Accuracy = 0.1491\n",
      "Epoch [5/512] Training-Loss = 0.8296 Train-Accuracy = 0.1704 Valid-Accuracy = 0.1491\n",
      "Epoch [6/512] Training-Loss = 0.8287 Train-Accuracy = 0.1713 Valid-Accuracy = 0.1491\n",
      "Epoch [7/512] Training-Loss = 0.8277 Train-Accuracy = 0.1723 Valid-Accuracy = 0.1491\n",
      "Epoch [8/512] Training-Loss = 0.8268 Train-Accuracy = 0.1732 Valid-Accuracy = 0.1491\n",
      "Epoch [9/512] Training-Loss = 0.8259 Train-Accuracy = 0.1741 Valid-Accuracy = 0.1491\n",
      "Epoch [10/512] Training-Loss = 0.8249 Train-Accuracy = 0.1751 Valid-Accuracy = 0.1491\n",
      "Epoch [11/512] Training-Loss = 0.8240 Train-Accuracy = 0.1760 Valid-Accuracy = 0.1491\n",
      "Epoch [12/512] Training-Loss = 0.8231 Train-Accuracy = 0.1769 Valid-Accuracy = 0.1491\n",
      "Epoch [13/512] Training-Loss = 0.8222 Train-Accuracy = 0.1778 Valid-Accuracy = 0.1491\n",
      "Epoch [14/512] Training-Loss = 0.8213 Train-Accuracy = 0.1787 Valid-Accuracy = 0.1491\n",
      "Epoch [15/512] Training-Loss = 0.8204 Train-Accuracy = 0.1796 Valid-Accuracy = 0.1491\n",
      "Epoch [16/512] Training-Loss = 0.8195 Train-Accuracy = 0.1805 Valid-Accuracy = 0.1491\n",
      "Epoch [17/512] Training-Loss = 0.8186 Train-Accuracy = 0.1814 Valid-Accuracy = 0.1491\n",
      "Epoch [18/512] Training-Loss = 0.8177 Train-Accuracy = 0.1823 Valid-Accuracy = 0.1491\n",
      "Epoch [19/512] Training-Loss = 0.8168 Train-Accuracy = 0.1832 Valid-Accuracy = 0.1491\n",
      "Epoch [20/512] Training-Loss = 0.8159 Train-Accuracy = 0.1841 Valid-Accuracy = 0.1491\n",
      "Epoch [21/512] Training-Loss = 0.8150 Train-Accuracy = 0.1850 Valid-Accuracy = 0.1491\n",
      "Epoch [22/512] Training-Loss = 0.8141 Train-Accuracy = 0.1859 Valid-Accuracy = 0.1491\n",
      "Epoch [23/512] Training-Loss = 0.8132 Train-Accuracy = 0.1868 Valid-Accuracy = 0.1491\n",
      "Epoch [24/512] Training-Loss = 0.8123 Train-Accuracy = 0.1877 Valid-Accuracy = 0.1491\n",
      "Epoch [25/512] Training-Loss = 0.8115 Train-Accuracy = 0.1885 Valid-Accuracy = 0.1491\n",
      "Epoch [26/512] Training-Loss = 0.8106 Train-Accuracy = 0.1894 Valid-Accuracy = 0.1491\n",
      "Epoch [27/512] Training-Loss = 0.8097 Train-Accuracy = 0.1903 Valid-Accuracy = 0.1491\n",
      "Epoch [28/512] Training-Loss = 0.8088 Train-Accuracy = 0.1912 Valid-Accuracy = 0.1491\n",
      "Epoch [29/512] Training-Loss = 0.8079 Train-Accuracy = 0.1921 Valid-Accuracy = 0.1491\n",
      "Epoch [30/512] Training-Loss = 0.8070 Train-Accuracy = 0.1930 Valid-Accuracy = 0.1491\n",
      "Epoch [31/512] Training-Loss = 0.8061 Train-Accuracy = 0.1939 Valid-Accuracy = 0.1491\n",
      "Epoch [32/512] Training-Loss = 0.8053 Train-Accuracy = 0.1947 Valid-Accuracy = 0.1491\n",
      "Epoch [33/512] Training-Loss = 0.8044 Train-Accuracy = 0.1956 Valid-Accuracy = 0.1491\n",
      "Epoch [34/512] Training-Loss = 0.8035 Train-Accuracy = 0.1965 Valid-Accuracy = 0.1491\n",
      "Epoch [35/512] Training-Loss = 0.8026 Train-Accuracy = 0.1974 Valid-Accuracy = 0.1491\n",
      "Epoch [36/512] Training-Loss = 0.8017 Train-Accuracy = 0.1983 Valid-Accuracy = 0.1491\n",
      "Epoch [37/512] Training-Loss = 0.8008 Train-Accuracy = 0.1992 Valid-Accuracy = 0.1491\n",
      "Epoch [38/512] Training-Loss = 0.7999 Train-Accuracy = 0.2001 Valid-Accuracy = 0.1491\n",
      "Epoch [39/512] Training-Loss = 0.7990 Train-Accuracy = 0.2010 Valid-Accuracy = 0.1491\n",
      "Epoch [40/512] Training-Loss = 0.7981 Train-Accuracy = 0.2019 Valid-Accuracy = 0.1491\n",
      "Epoch [41/512] Training-Loss = 0.7972 Train-Accuracy = 0.2028 Valid-Accuracy = 0.1491\n",
      "Epoch [42/512] Training-Loss = 0.7962 Train-Accuracy = 0.2038 Valid-Accuracy = 0.1491\n",
      "Epoch [43/512] Training-Loss = 0.7953 Train-Accuracy = 0.2047 Valid-Accuracy = 0.1491\n",
      "Epoch [44/512] Training-Loss = 0.7944 Train-Accuracy = 0.2056 Valid-Accuracy = 0.1491\n",
      "Epoch [45/512] Training-Loss = 0.7935 Train-Accuracy = 0.2065 Valid-Accuracy = 0.1491\n",
      "Epoch [46/512] Training-Loss = 0.7925 Train-Accuracy = 0.2075 Valid-Accuracy = 0.1491\n",
      "Epoch [47/512] Training-Loss = 0.7916 Train-Accuracy = 0.2084 Valid-Accuracy = 0.1491\n",
      "Epoch [48/512] Training-Loss = 0.7906 Train-Accuracy = 0.2094 Valid-Accuracy = 0.1491\n",
      "Epoch [49/512] Training-Loss = 0.7897 Train-Accuracy = 0.2103 Valid-Accuracy = 0.1491\n",
      "Epoch [50/512] Training-Loss = 0.7887 Train-Accuracy = 0.2113 Valid-Accuracy = 0.1491\n",
      "Epoch [51/512] Training-Loss = 0.7877 Train-Accuracy = 0.2123 Valid-Accuracy = 0.1491\n",
      "Epoch [52/512] Training-Loss = 0.7867 Train-Accuracy = 0.2133 Valid-Accuracy = 0.1491\n",
      "Epoch [53/512] Training-Loss = 0.7857 Train-Accuracy = 0.2143 Valid-Accuracy = 0.1491\n",
      "Epoch [54/512] Training-Loss = 0.7847 Train-Accuracy = 0.2153 Valid-Accuracy = 0.1491\n",
      "Epoch [55/512] Training-Loss = 0.7837 Train-Accuracy = 0.2163 Valid-Accuracy = 0.1491\n",
      "Epoch [56/512] Training-Loss = 0.7826 Train-Accuracy = 0.2174 Valid-Accuracy = 0.1491\n",
      "Epoch [57/512] Training-Loss = 0.7816 Train-Accuracy = 0.2184 Valid-Accuracy = 0.1491\n",
      "Epoch [58/512] Training-Loss = 0.7805 Train-Accuracy = 0.2195 Valid-Accuracy = 0.1491\n",
      "Epoch [59/512] Training-Loss = 0.7795 Train-Accuracy = 0.2205 Valid-Accuracy = 0.1491\n",
      "Epoch [60/512] Training-Loss = 0.7784 Train-Accuracy = 0.2216 Valid-Accuracy = 0.1491\n",
      "Epoch [61/512] Training-Loss = 0.7773 Train-Accuracy = 0.2227 Valid-Accuracy = 0.1491\n",
      "Epoch [62/512] Training-Loss = 0.7762 Train-Accuracy = 0.2238 Valid-Accuracy = 0.1491\n",
      "Epoch [63/512] Training-Loss = 0.7750 Train-Accuracy = 0.2250 Valid-Accuracy = 0.1491\n",
      "Epoch [64/512] Training-Loss = 0.7738 Train-Accuracy = 0.2262 Valid-Accuracy = 0.1491\n",
      "Epoch [65/512] Training-Loss = 0.7726 Train-Accuracy = 0.2274 Valid-Accuracy = 0.1491\n",
      "Epoch [66/512] Training-Loss = 0.7714 Train-Accuracy = 0.2286 Valid-Accuracy = 0.1491\n",
      "Epoch [67/512] Training-Loss = 0.7702 Train-Accuracy = 0.2298 Valid-Accuracy = 0.1491\n",
      "Epoch [68/512] Training-Loss = 0.7689 Train-Accuracy = 0.2311 Valid-Accuracy = 0.1491\n",
      "Epoch [69/512] Training-Loss = 0.7677 Train-Accuracy = 0.2323 Valid-Accuracy = 0.1491\n",
      "Epoch [70/512] Training-Loss = 0.7664 Train-Accuracy = 0.2336 Valid-Accuracy = 0.1491\n",
      "Epoch [71/512] Training-Loss = 0.7651 Train-Accuracy = 0.2349 Valid-Accuracy = 0.1491\n",
      "Epoch [72/512] Training-Loss = 0.7637 Train-Accuracy = 0.2363 Valid-Accuracy = 0.1491\n",
      "Epoch [73/512] Training-Loss = 0.7624 Train-Accuracy = 0.2376 Valid-Accuracy = 0.1491\n",
      "Epoch [74/512] Training-Loss = 0.7610 Train-Accuracy = 0.2390 Valid-Accuracy = 0.1491\n",
      "Epoch [75/512] Training-Loss = 0.7596 Train-Accuracy = 0.2404 Valid-Accuracy = 0.1491\n",
      "Epoch [76/512] Training-Loss = 0.7582 Train-Accuracy = 0.2418 Valid-Accuracy = 0.1491\n",
      "Epoch [77/512] Training-Loss = 0.7567 Train-Accuracy = 0.2433 Valid-Accuracy = 0.1491\n",
      "Epoch [78/512] Training-Loss = 0.7552 Train-Accuracy = 0.2448 Valid-Accuracy = 0.1491\n",
      "Epoch [79/512] Training-Loss = 0.7537 Train-Accuracy = 0.2463 Valid-Accuracy = 0.1491\n",
      "Epoch [80/512] Training-Loss = 0.7521 Train-Accuracy = 0.2479 Valid-Accuracy = 0.1491\n",
      "Epoch [81/512] Training-Loss = 0.7505 Train-Accuracy = 0.2495 Valid-Accuracy = 0.1491\n",
      "Epoch [82/512] Training-Loss = 0.7489 Train-Accuracy = 0.2511 Valid-Accuracy = 0.1491\n",
      "Epoch [83/512] Training-Loss = 0.7472 Train-Accuracy = 0.2528 Valid-Accuracy = 0.1491\n",
      "Epoch [84/512] Training-Loss = 0.7455 Train-Accuracy = 0.2545 Valid-Accuracy = 0.1491\n",
      "Epoch [85/512] Training-Loss = 0.7437 Train-Accuracy = 0.2563 Valid-Accuracy = 0.1491\n",
      "Epoch [86/512] Training-Loss = 0.7419 Train-Accuracy = 0.2581 Valid-Accuracy = 0.1491\n",
      "Epoch [87/512] Training-Loss = 0.7401 Train-Accuracy = 0.2599 Valid-Accuracy = 0.1491\n",
      "Epoch [88/512] Training-Loss = 0.7381 Train-Accuracy = 0.2619 Valid-Accuracy = 0.1491\n",
      "Epoch [89/512] Training-Loss = 0.7362 Train-Accuracy = 0.2638 Valid-Accuracy = 0.1491\n",
      "Epoch [90/512] Training-Loss = 0.7342 Train-Accuracy = 0.2658 Valid-Accuracy = 0.1491\n",
      "Epoch [91/512] Training-Loss = 0.7321 Train-Accuracy = 0.2679 Valid-Accuracy = 0.1491\n",
      "Epoch [92/512] Training-Loss = 0.7299 Train-Accuracy = 0.2701 Valid-Accuracy = 0.1491\n",
      "Epoch [93/512] Training-Loss = 0.7277 Train-Accuracy = 0.2723 Valid-Accuracy = 0.1491\n",
      "Epoch [94/512] Training-Loss = 0.7254 Train-Accuracy = 0.2746 Valid-Accuracy = 0.1491\n",
      "Epoch [95/512] Training-Loss = 0.7231 Train-Accuracy = 0.2769 Valid-Accuracy = 0.1491\n",
      "Epoch [96/512] Training-Loss = 0.7206 Train-Accuracy = 0.2794 Valid-Accuracy = 0.1491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/512] Training-Loss = 0.7181 Train-Accuracy = 0.2819 Valid-Accuracy = 0.1491\n",
      "Epoch [98/512] Training-Loss = 0.7155 Train-Accuracy = 0.2845 Valid-Accuracy = 0.1491\n",
      "Epoch [99/512] Training-Loss = 0.7128 Train-Accuracy = 0.2872 Valid-Accuracy = 0.1491\n",
      "Epoch [100/512] Training-Loss = 0.7100 Train-Accuracy = 0.2900 Valid-Accuracy = 0.1491\n",
      "Epoch [101/512] Training-Loss = 0.7072 Train-Accuracy = 0.2928 Valid-Accuracy = 0.1491\n",
      "Epoch [102/512] Training-Loss = 0.7042 Train-Accuracy = 0.2958 Valid-Accuracy = 0.1739\n",
      "Epoch [103/512] Training-Loss = 0.7012 Train-Accuracy = 0.2988 Valid-Accuracy = 0.2888\n",
      "Epoch [104/512] Training-Loss = 0.6981 Train-Accuracy = 0.3019 Valid-Accuracy = 0.3789\n",
      "Epoch [105/512] Training-Loss = 0.6948 Train-Accuracy = 0.3052 Valid-Accuracy = 0.4907\n",
      "Epoch [106/512] Training-Loss = 0.6914 Train-Accuracy = 0.3086 Valid-Accuracy = 0.5714\n",
      "Epoch [107/512] Training-Loss = 0.6879 Train-Accuracy = 0.3121 Valid-Accuracy = 0.6677\n",
      "Epoch [108/512] Training-Loss = 0.6843 Train-Accuracy = 0.3157 Valid-Accuracy = 0.7484\n",
      "Epoch [109/512] Training-Loss = 0.6806 Train-Accuracy = 0.3194 Valid-Accuracy = 0.8230\n",
      "Epoch [110/512] Training-Loss = 0.6768 Train-Accuracy = 0.3232 Valid-Accuracy = 0.8323\n",
      "Epoch [111/512] Training-Loss = 0.6729 Train-Accuracy = 0.3271 Valid-Accuracy = 0.8292\n",
      "Epoch [112/512] Training-Loss = 0.6689 Train-Accuracy = 0.3311 Valid-Accuracy = 0.8292\n",
      "Epoch [113/512] Training-Loss = 0.6647 Train-Accuracy = 0.3353 Valid-Accuracy = 0.8323\n",
      "Epoch [114/512] Training-Loss = 0.6604 Train-Accuracy = 0.3396 Valid-Accuracy = 0.8323\n",
      "Epoch [115/512] Training-Loss = 0.6560 Train-Accuracy = 0.3440 Valid-Accuracy = 0.8323\n",
      "Epoch [116/512] Training-Loss = 0.6515 Train-Accuracy = 0.3485 Valid-Accuracy = 0.8354\n",
      "Epoch [117/512] Training-Loss = 0.6469 Train-Accuracy = 0.3531 Valid-Accuracy = 0.8354\n",
      "Epoch [118/512] Training-Loss = 0.6423 Train-Accuracy = 0.3577 Valid-Accuracy = 0.8354\n",
      "Epoch [119/512] Training-Loss = 0.6375 Train-Accuracy = 0.3625 Valid-Accuracy = 0.8385\n",
      "Epoch [120/512] Training-Loss = 0.6328 Train-Accuracy = 0.3672 Valid-Accuracy = 0.8385\n",
      "Epoch [121/512] Training-Loss = 0.6279 Train-Accuracy = 0.3721 Valid-Accuracy = 0.8385\n",
      "Epoch [122/512] Training-Loss = 0.6229 Train-Accuracy = 0.3771 Valid-Accuracy = 0.8385\n",
      "Epoch [123/512] Training-Loss = 0.6179 Train-Accuracy = 0.3821 Valid-Accuracy = 0.8416\n",
      "Epoch [124/512] Training-Loss = 0.6128 Train-Accuracy = 0.3872 Valid-Accuracy = 0.8416\n",
      "Epoch [125/512] Training-Loss = 0.6077 Train-Accuracy = 0.3923 Valid-Accuracy = 0.8416\n",
      "Epoch [126/512] Training-Loss = 0.6026 Train-Accuracy = 0.3974 Valid-Accuracy = 0.8416\n",
      "Epoch [127/512] Training-Loss = 0.5976 Train-Accuracy = 0.4024 Valid-Accuracy = 0.8416\n",
      "Epoch [128/512] Training-Loss = 0.5925 Train-Accuracy = 0.4075 Valid-Accuracy = 0.8416\n",
      "Epoch [129/512] Training-Loss = 0.5875 Train-Accuracy = 0.4125 Valid-Accuracy = 0.8447\n",
      "Epoch [130/512] Training-Loss = 0.5825 Train-Accuracy = 0.4175 Valid-Accuracy = 0.8447\n",
      "Epoch [131/512] Training-Loss = 0.5775 Train-Accuracy = 0.4225 Valid-Accuracy = 0.8447\n",
      "Epoch [132/512] Training-Loss = 0.5726 Train-Accuracy = 0.4274 Valid-Accuracy = 0.8447\n",
      "Epoch [133/512] Training-Loss = 0.5676 Train-Accuracy = 0.4324 Valid-Accuracy = 0.8447\n",
      "Epoch [134/512] Training-Loss = 0.5628 Train-Accuracy = 0.4372 Valid-Accuracy = 0.8447\n",
      "Epoch [135/512] Training-Loss = 0.5580 Train-Accuracy = 0.4420 Valid-Accuracy = 0.8447\n",
      "Epoch [136/512] Training-Loss = 0.5533 Train-Accuracy = 0.4467 Valid-Accuracy = 0.8447\n",
      "Epoch [137/512] Training-Loss = 0.5487 Train-Accuracy = 0.4513 Valid-Accuracy = 0.8447\n",
      "Epoch [138/512] Training-Loss = 0.5441 Train-Accuracy = 0.4559 Valid-Accuracy = 0.8447\n",
      "Epoch [139/512] Training-Loss = 0.5396 Train-Accuracy = 0.4604 Valid-Accuracy = 0.8447\n",
      "Epoch [140/512] Training-Loss = 0.5352 Train-Accuracy = 0.4648 Valid-Accuracy = 0.8478\n",
      "Epoch [141/512] Training-Loss = 0.5309 Train-Accuracy = 0.4691 Valid-Accuracy = 0.8478\n",
      "Epoch [142/512] Training-Loss = 0.5266 Train-Accuracy = 0.4734 Valid-Accuracy = 0.8478\n",
      "Epoch [143/512] Training-Loss = 0.5224 Train-Accuracy = 0.4776 Valid-Accuracy = 0.8478\n",
      "Epoch [144/512] Training-Loss = 0.5183 Train-Accuracy = 0.4817 Valid-Accuracy = 0.8478\n",
      "Epoch [145/512] Training-Loss = 0.5144 Train-Accuracy = 0.4856 Valid-Accuracy = 0.8478\n",
      "Epoch [146/512] Training-Loss = 0.5104 Train-Accuracy = 0.4896 Valid-Accuracy = 0.8478\n",
      "Epoch [147/512] Training-Loss = 0.5066 Train-Accuracy = 0.4934 Valid-Accuracy = 0.8478\n",
      "Epoch [148/512] Training-Loss = 0.5028 Train-Accuracy = 0.4972 Valid-Accuracy = 0.8478\n",
      "Epoch [149/512] Training-Loss = 0.4992 Train-Accuracy = 0.5008 Valid-Accuracy = 0.8478\n",
      "Epoch [150/512] Training-Loss = 0.4956 Train-Accuracy = 0.5044 Valid-Accuracy = 0.8478\n",
      "Epoch [151/512] Training-Loss = 0.4922 Train-Accuracy = 0.5078 Valid-Accuracy = 0.8478\n",
      "Epoch [152/512] Training-Loss = 0.4888 Train-Accuracy = 0.5112 Valid-Accuracy = 0.8478\n",
      "Epoch [153/512] Training-Loss = 0.4856 Train-Accuracy = 0.5144 Valid-Accuracy = 0.8478\n",
      "Epoch [154/512] Training-Loss = 0.4824 Train-Accuracy = 0.5176 Valid-Accuracy = 0.8478\n",
      "Epoch [155/512] Training-Loss = 0.4793 Train-Accuracy = 0.5207 Valid-Accuracy = 0.8478\n",
      "Epoch [156/512] Training-Loss = 0.4763 Train-Accuracy = 0.5237 Valid-Accuracy = 0.8478\n",
      "Epoch [157/512] Training-Loss = 0.4734 Train-Accuracy = 0.5266 Valid-Accuracy = 0.8478\n",
      "Epoch [158/512] Training-Loss = 0.4706 Train-Accuracy = 0.5294 Valid-Accuracy = 0.8478\n",
      "Epoch [159/512] Training-Loss = 0.4680 Train-Accuracy = 0.5320 Valid-Accuracy = 0.8478\n",
      "Epoch [160/512] Training-Loss = 0.4654 Train-Accuracy = 0.5346 Valid-Accuracy = 0.8478\n",
      "Epoch [161/512] Training-Loss = 0.4630 Train-Accuracy = 0.5370 Valid-Accuracy = 0.8478\n",
      "Epoch [162/512] Training-Loss = 0.4606 Train-Accuracy = 0.5394 Valid-Accuracy = 0.8478\n",
      "Epoch [163/512] Training-Loss = 0.4584 Train-Accuracy = 0.5416 Valid-Accuracy = 0.8478\n",
      "Epoch [164/512] Training-Loss = 0.4562 Train-Accuracy = 0.5438 Valid-Accuracy = 0.8478\n",
      "Epoch [165/512] Training-Loss = 0.4542 Train-Accuracy = 0.5458 Valid-Accuracy = 0.8478\n",
      "Epoch [166/512] Training-Loss = 0.4523 Train-Accuracy = 0.5477 Valid-Accuracy = 0.8478\n",
      "Epoch [167/512] Training-Loss = 0.4505 Train-Accuracy = 0.5495 Valid-Accuracy = 0.8478\n",
      "Epoch [168/512] Training-Loss = 0.4488 Train-Accuracy = 0.5512 Valid-Accuracy = 0.8478\n",
      "Epoch [169/512] Training-Loss = 0.4471 Train-Accuracy = 0.5529 Valid-Accuracy = 0.8478\n",
      "Epoch [170/512] Training-Loss = 0.4456 Train-Accuracy = 0.5544 Valid-Accuracy = 0.8509\n",
      "Epoch [171/512] Training-Loss = 0.4442 Train-Accuracy = 0.5558 Valid-Accuracy = 0.8509\n",
      "Epoch [172/512] Training-Loss = 0.4429 Train-Accuracy = 0.5571 Valid-Accuracy = 0.8509\n",
      "Epoch [173/512] Training-Loss = 0.4416 Train-Accuracy = 0.5584 Valid-Accuracy = 0.8509\n",
      "Epoch [174/512] Training-Loss = 0.4405 Train-Accuracy = 0.5595 Valid-Accuracy = 0.8509\n",
      "Epoch [175/512] Training-Loss = 0.4394 Train-Accuracy = 0.5606 Valid-Accuracy = 0.8509\n",
      "Epoch [176/512] Training-Loss = 0.4384 Train-Accuracy = 0.5616 Valid-Accuracy = 0.8509\n",
      "Epoch [177/512] Training-Loss = 0.4374 Train-Accuracy = 0.5626 Valid-Accuracy = 0.8509\n",
      "Epoch [178/512] Training-Loss = 0.4366 Train-Accuracy = 0.5634 Valid-Accuracy = 0.8509\n",
      "Epoch [179/512] Training-Loss = 0.4357 Train-Accuracy = 0.5643 Valid-Accuracy = 0.8509\n",
      "Epoch [180/512] Training-Loss = 0.4350 Train-Accuracy = 0.5650 Valid-Accuracy = 0.8509\n",
      "Epoch [181/512] Training-Loss = 0.4343 Train-Accuracy = 0.5657 Valid-Accuracy = 0.8509\n",
      "Epoch [182/512] Training-Loss = 0.4337 Train-Accuracy = 0.5663 Valid-Accuracy = 0.8509\n",
      "Epoch [183/512] Training-Loss = 0.4331 Train-Accuracy = 0.5669 Valid-Accuracy = 0.8509\n",
      "Epoch [184/512] Training-Loss = 0.4325 Train-Accuracy = 0.5675 Valid-Accuracy = 0.8509\n",
      "Epoch [185/512] Training-Loss = 0.4320 Train-Accuracy = 0.5680 Valid-Accuracy = 0.8509\n",
      "Epoch [186/512] Training-Loss = 0.4316 Train-Accuracy = 0.5684 Valid-Accuracy = 0.8509\n",
      "Epoch [187/512] Training-Loss = 0.4312 Train-Accuracy = 0.5688 Valid-Accuracy = 0.8509\n",
      "Epoch [188/512] Training-Loss = 0.4308 Train-Accuracy = 0.5692 Valid-Accuracy = 0.8509\n",
      "Epoch [189/512] Training-Loss = 0.4304 Train-Accuracy = 0.5696 Valid-Accuracy = 0.8509\n",
      "Epoch [190/512] Training-Loss = 0.4301 Train-Accuracy = 0.5699 Valid-Accuracy = 0.8509\n",
      "Epoch [191/512] Training-Loss = 0.4298 Train-Accuracy = 0.5702 Valid-Accuracy = 0.8509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [192/512] Training-Loss = 0.4296 Train-Accuracy = 0.5704 Valid-Accuracy = 0.8509\n",
      "Epoch [193/512] Training-Loss = 0.4293 Train-Accuracy = 0.5707 Valid-Accuracy = 0.8509\n",
      "Epoch [194/512] Training-Loss = 0.4291 Train-Accuracy = 0.5709 Valid-Accuracy = 0.8509\n",
      "Epoch [195/512] Training-Loss = 0.4289 Train-Accuracy = 0.5711 Valid-Accuracy = 0.8509\n",
      "Epoch [196/512] Training-Loss = 0.4287 Train-Accuracy = 0.5713 Valid-Accuracy = 0.8509\n",
      "Epoch [197/512] Training-Loss = 0.4286 Train-Accuracy = 0.5714 Valid-Accuracy = 0.8509\n",
      "Epoch [198/512] Training-Loss = 0.4284 Train-Accuracy = 0.5716 Valid-Accuracy = 0.8509\n",
      "Epoch [199/512] Training-Loss = 0.4283 Train-Accuracy = 0.5717 Valid-Accuracy = 0.8509\n",
      "Epoch [200/512] Training-Loss = 0.4281 Train-Accuracy = 0.5719 Valid-Accuracy = 0.8509\n",
      "Epoch [201/512] Training-Loss = 0.4280 Train-Accuracy = 0.5720 Valid-Accuracy = 0.8509\n",
      "Epoch [202/512] Training-Loss = 0.4279 Train-Accuracy = 0.5721 Valid-Accuracy = 0.8509\n",
      "Epoch [203/512] Training-Loss = 0.4279 Train-Accuracy = 0.5721 Valid-Accuracy = 0.8509\n",
      "Epoch [204/512] Training-Loss = 0.4278 Train-Accuracy = 0.5722 Valid-Accuracy = 0.8509\n",
      "Epoch [205/512] Training-Loss = 0.4277 Train-Accuracy = 0.5723 Valid-Accuracy = 0.8509\n",
      "Epoch [206/512] Training-Loss = 0.4277 Train-Accuracy = 0.5723 Valid-Accuracy = 0.8509\n",
      "Epoch [207/512] Training-Loss = 0.4276 Train-Accuracy = 0.5724 Valid-Accuracy = 0.8509\n",
      "Epoch [208/512] Training-Loss = 0.4276 Train-Accuracy = 0.5724 Valid-Accuracy = 0.8509\n",
      "Epoch [209/512] Training-Loss = 0.4275 Train-Accuracy = 0.5725 Valid-Accuracy = 0.8509\n",
      "Epoch [210/512] Training-Loss = 0.4275 Train-Accuracy = 0.5725 Valid-Accuracy = 0.8509\n",
      "Epoch [211/512] Training-Loss = 0.4275 Train-Accuracy = 0.5725 Valid-Accuracy = 0.8509\n",
      "Epoch [212/512] Training-Loss = 0.4274 Train-Accuracy = 0.5726 Valid-Accuracy = 0.8509\n",
      "Epoch [213/512] Training-Loss = 0.4274 Train-Accuracy = 0.5726 Valid-Accuracy = 0.8509\n",
      "Epoch [214/512] Training-Loss = 0.4274 Train-Accuracy = 0.5726 Valid-Accuracy = 0.8509\n",
      "Epoch [215/512] Training-Loss = 0.4274 Train-Accuracy = 0.5726 Valid-Accuracy = 0.8509\n",
      "Epoch [216/512] Training-Loss = 0.4274 Train-Accuracy = 0.5726 Valid-Accuracy = 0.8509\n",
      "Epoch [217/512] Training-Loss = 0.4274 Train-Accuracy = 0.5726 Valid-Accuracy = 0.8509\n",
      "Epoch [218/512] Training-Loss = 0.4274 Train-Accuracy = 0.5726 Valid-Accuracy = 0.8509\n",
      "Epoch [219/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [220/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [221/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [222/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [223/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [224/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [225/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [226/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [227/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [228/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [229/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [230/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [231/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [232/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [233/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [234/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [235/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [236/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [237/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [238/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [239/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [240/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [241/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [242/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [243/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [244/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [245/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [246/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [247/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [248/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [249/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [250/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [251/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [252/512] Training-Loss = 0.4273 Train-Accuracy = 0.5727 Valid-Accuracy = 0.8509\n",
      "Epoch [253/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [254/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [255/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [256/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [257/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [258/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [259/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [260/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [261/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [262/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [263/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [264/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [265/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [266/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [267/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [268/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [269/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [270/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [271/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [272/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [273/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [274/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [275/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [276/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [277/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [278/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [279/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [280/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [281/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [282/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [283/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [284/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [285/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [286/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n",
      "Epoch [287/512] Training-Loss = 0.4272 Train-Accuracy = 0.5728 Valid-Accuracy = 0.8509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [288/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [289/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [290/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [291/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [292/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [293/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [294/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [295/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [296/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [297/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [298/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [299/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [300/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [301/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [302/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [303/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [304/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [305/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [306/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [307/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [308/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [309/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [310/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [311/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [312/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [313/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [314/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [315/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [316/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [317/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [318/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [319/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [320/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [321/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [322/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [323/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [324/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [325/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [326/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [327/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [328/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [329/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [330/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [331/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [332/512] Training-Loss = 0.4271 Train-Accuracy = 0.5729 Valid-Accuracy = 0.8509\n",
      "Epoch [333/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [334/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [335/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [336/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [337/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [338/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [339/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [340/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [341/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [342/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [343/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [344/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [345/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [346/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [347/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [348/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [349/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [350/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [351/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [352/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [353/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [354/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [355/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [356/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [357/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [358/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [359/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [360/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [361/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [362/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [363/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [364/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [365/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [366/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [367/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [368/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [369/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [370/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [371/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [372/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [373/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [374/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [375/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [376/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [377/512] Training-Loss = 0.4270 Train-Accuracy = 0.5730 Valid-Accuracy = 0.8509\n",
      "Epoch [378/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [379/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [380/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [381/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [382/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [383/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [384/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [385/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [386/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [387/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [388/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [389/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [390/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [391/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [392/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [393/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [394/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [395/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [396/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [397/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [398/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [399/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [400/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [401/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [402/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [403/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [404/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [405/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [406/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [407/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [408/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [409/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [410/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [411/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [412/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [413/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [414/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [415/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [416/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [417/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [418/512] Training-Loss = 0.4269 Train-Accuracy = 0.5731 Valid-Accuracy = 0.8509\n",
      "Epoch [419/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [420/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [421/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [422/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [423/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [424/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [425/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [426/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [427/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [428/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [429/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [430/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [431/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [432/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [433/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [434/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [435/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [436/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [437/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [438/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [439/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [440/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [441/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [442/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [443/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [444/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [445/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [446/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [447/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [448/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [449/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [450/512] Training-Loss = 0.4268 Train-Accuracy = 0.5732 Valid-Accuracy = 0.8509\n",
      "Epoch [451/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [452/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [453/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [454/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [455/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [456/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [457/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [458/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [459/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [460/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [461/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [462/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [463/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [464/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [465/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [466/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [467/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [468/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [469/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [470/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [471/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [472/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [473/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [474/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [475/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [476/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [477/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n",
      "Epoch [478/512] Training-Loss = 0.4267 Train-Accuracy = 0.5733 Valid-Accuracy = 0.8509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [479/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [480/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [481/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [482/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [483/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [484/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [485/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [486/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [487/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [488/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [489/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [490/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [491/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [492/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [493/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [494/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [495/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [496/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [497/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [498/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [499/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [500/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [501/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [502/512] Training-Loss = 0.4266 Train-Accuracy = 0.5734 Valid-Accuracy = 0.8509\n",
      "Epoch [503/512] Training-Loss = 0.4265 Train-Accuracy = 0.5735 Valid-Accuracy = 0.8509\n",
      "Epoch [504/512] Training-Loss = 0.4265 Train-Accuracy = 0.5735 Valid-Accuracy = 0.8509\n",
      "Epoch [505/512] Training-Loss = 0.4265 Train-Accuracy = 0.5735 Valid-Accuracy = 0.8509\n",
      "Epoch [506/512] Training-Loss = 0.4265 Train-Accuracy = 0.5735 Valid-Accuracy = 0.8509\n",
      "Epoch [507/512] Training-Loss = 0.4265 Train-Accuracy = 0.5735 Valid-Accuracy = 0.8509\n",
      "Epoch [508/512] Training-Loss = 0.4265 Train-Accuracy = 0.5735 Valid-Accuracy = 0.8509\n",
      "Epoch [509/512] Training-Loss = 0.4265 Train-Accuracy = 0.5735 Valid-Accuracy = 0.8509\n",
      "Epoch [510/512] Training-Loss = 0.4265 Train-Accuracy = 0.5735 Valid-Accuracy = 0.8509\n",
      "Epoch [511/512] Training-Loss = 0.4265 Train-Accuracy = 0.5735 Valid-Accuracy = 0.8509\n",
      "Epoch [512/512] Training-Loss = 0.4265 Train-Accuracy = 0.5735 Valid-Accuracy = 0.8509\n"
     ]
    }
   ],
   "source": [
    "valid_acc_list = []\n",
    "vaild_acc_list = []\n",
    "model_list = []\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    predicted = model(x_train).to(device)\n",
    "    \n",
    "\n",
    "    loss = lossfn(predicted,y_train)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    val_acc = Validate(x_test,y_test.to(torch.int))\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{n_epochs}] Training-Loss = {loss.item():.4f} Train-Accuracy = {1-loss.item():.4f} Valid-Accuracy = {val_acc:.4f}')\n",
    "    val_acc_list.append(val_acc)\n",
    "    training_acc_list.append(1-loss.item())\n",
    "    model_list.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Training Accuracy =  0.5734947621822357\n",
      "Maximum Validation Accuracy =  0.8509316770186336\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum Training Accuracy = \", max(training_acc_list))\n",
    "print(\"Maximum Validation Accuracy = \",max(val_acc_list) )\n",
    "model = model_list[training_acc_list.index(max(training_acc_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Confusion Matrix for Train Data : \n",
      "         True Positive =  0            True Negetive =  195\n",
      "        False Positive =  2           False Negetive =  1091\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Total Cases : 1288\n",
      "\n",
      "Accuracy  :  0.8470496894409938\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-353-d9204d447669>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mconfusionMatrixPrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-259-1f503c6f9974>\u001b[0m in \u001b[0;36mconfusionMatrixPrint\u001b[1;34m(P, Y, dataType)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mprec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTT\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mFT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTT\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mTF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mprec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mprec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Precision : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Recall    : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "predicted = model(x_train).to(device)\n",
    "predicted = torch.max(predicted.data,1)[1]\n",
    "confusionMatrixPrint(predicted.to('cpu').numpy(),y_train.to('cpu').numpy(),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Confusion Matrix for Validation Data \n",
      "\n",
      "         True Positive =  1            True Negetive =  47\n",
      "        False Positive =  1           False Negetive =  273\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Total Cases : 322\n",
      "\n",
      "Accuracy  :  0.8509316770186336\n",
      "Precision :  0.5\n",
      "Recall    :  0.020833333333333332\n",
      "F1 Score  :  0.039999999999999994\n",
      "\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "predicted = model(x_test).to(device)\n",
    "predicted = torch.max(predicted.data,1)[1]\n",
    "confusionMatrixPrint(predicted.to('cpu').numpy(),y_test.to('cpu').numpy(),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_acc_list.clear()\n",
    "training_acc_list.clear()\n",
    "model_list.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Nueral Network Based Classifier on Bag of Words\n",
    "\n",
    "## Nueral Network of :\n",
    "     - Input Layer\n",
    "     - Embedding Layer\n",
    "     - Bidirectional LSTM\n",
    "     - BatchNormalization\n",
    "     - Bidirectional LSTM\n",
    "     - BatchNormalization\n",
    "     - Bidirectional LSTM\n",
    "     - Flatten Layer\n",
    "     - Dense Layer\n",
    "     - Dense Layer\n",
    "     - Dropout Layer\n",
    "     - Dense Layer\n",
    "     - Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Embedding,Bidirectional,LSTM,BatchNormalization,Dense,GlobalMaxPool1D,Dropout,Masking,Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from filters import train_test_splitter, get_users_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_users_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6533 words are used\n",
      "\n",
      "6533\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df.tweet_text)\n",
    "print(f\"{len(tokenizer.word_index)} words are used\\n\")\n",
    "\n",
    "counts = tokenizer.word_counts\n",
    "print(len(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_size=7000\n",
    "vocab_size = word_size\n",
    "tokenizer = Tokenizer(num_words=word_size)\n",
    "\n",
    "tokenizer.fit_on_texts(df.tweet_text)\n",
    "tokenized = tokenizer.texts_to_sequences(df.tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average words length of all tweets>> 13.114906832298137\n",
      "Maximum words length of a tweet_text >> 40\n",
      "Pad all sequences into size of 18\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(s) for s in tokenized]\n",
    "print(f\"Average words length of all tweets>> {np.mean(lengths)}\")\n",
    "print(f\"Maximum words length of a tweet_text >> {np.max(lengths)}\")\n",
    "\n",
    "sequence_size = 18\n",
    "print(f\"Pad all sequences into size of {sequence_size}\")\n",
    "\n",
    "padded = pad_sequences(tokenized,maxlen=sequence_size,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(padded, df.Annotation.values, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1288, 18), (322, 18), (1288,), (322,))"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape,y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 2)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_size=20\n",
    "hidden_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bilstm_model():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=[sequence_size]))\n",
    "    model.add(Embedding(vocab_size,word_vec_size,input_length=sequence_size))\n",
    "    \n",
    "    \n",
    "    model.add(Bidirectional(LSTM(hidden_size,return_sequences=True)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Bidirectional(LSTM(int(hidden_size/2),return_sequences=True)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Bidirectional(LSTM(int(hidden_size/2),return_sequences=True)))\n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.output_shape\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    \n",
    "    # model = keras.models.Model(X,Y)\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy',mode='min',patience=4,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 18, 20)            140000    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 18, 256)           152576    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 18, 256)           1024      \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 18, 128)           164352    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 18, 128)           512       \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 18, 128)           98816     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,180,514\n",
      "Trainable params: 1,179,746\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_bilstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 2s 338ms/step - loss: 0.0333 - accuracy: 0.9845 - val_loss: 0.8000 - val_accuracy: 0.8101\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 2s 324ms/step - loss: 0.0364 - accuracy: 0.9825 - val_loss: 0.6600 - val_accuracy: 0.8333\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 2s 306ms/step - loss: 0.0846 - accuracy: 0.9350 - val_loss: 0.7987 - val_accuracy: 0.8488\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 2s 286ms/step - loss: 0.0730 - accuracy: 0.9845 - val_loss: 0.8080 - val_accuracy: 0.8411\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 2s 302ms/step - loss: 0.0418 - accuracy: 0.9854 - val_loss: 0.8955 - val_accuracy: 0.8450\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train,y_train,epochs=100,batch_size = 256, validation_split=0.2, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 27ms/step - loss: 0.6091 - accuracy: 0.8851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6090861558914185, 0.8850931525230408]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev = model.evaluate(x_test,to_categorical(y_test,num_classes=2))\n",
    "ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8488371968269348"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(hist.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(x_test)\n",
    "pred = np.argmax(pred, axis=-1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 285 correct predictions out of 322\n",
      "Total 37 wrong predictions out of 322\n",
      "Accuracy =  88.50931677018633  %\n"
     ]
    }
   ],
   "source": [
    "total_test = len(y_test)\n",
    "correct_pred = 0\n",
    "wrong_pred = 0\n",
    "\n",
    "for i in range(total_test):\n",
    "    if y_test[i] == pred[i]:\n",
    "        correct_pred += 1\n",
    "    else:\n",
    "        wrong_pred += 1\n",
    "\n",
    "print(f\"Total {correct_pred} correct predictions out of {total_test}\")\n",
    "print(f\"Total {wrong_pred} wrong predictions out of {total_test}\")\n",
    "\n",
    "print(\"Accuracy = \", (correct_pred/total_test)*100, \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Confusion Matrix for Train Data : \n",
      "         True Positive =  127            True Negetive =  71\n",
      "        False Positive =  27           False Negetive =  1063\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Total Cases : 1288\n",
      "\n",
      "Accuracy  :  0.9239130434782609\n",
      "Precision :  0.8246753246753247\n",
      "Recall    :  0.6414141414141414\n",
      "F1 Score  :  0.7215909090909091\n",
      "\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "confusionMatrixPrint(np.argmax(model(x_train), axis=-1),np.argmax(y_train,axis = -1),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Confusion Matrix for Validation Data \n",
      "\n",
      "         True Positive =  14            True Negetive =  31\n",
      "        False Positive =  6           False Negetive =  271\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Total Cases : 322\n",
      "\n",
      "Accuracy  :  0.8850931677018633\n",
      "Precision :  0.7\n",
      "Recall    :  0.3111111111111111\n",
      "F1 Score  :  0.43076923076923074\n",
      "\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "confusionMatrixPrint(np.argmax(model(x_test), axis=-1),y_test,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from keras.layers import Input,Embedding,Bidirectional,LSTM,BatchNormalization,Dense,GlobalMaxPool1D,Dropout,Masking,Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from filters import train_test_splitter, get_users_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_users_dataframe()\n",
    "tweet_text_list = list(df.tweet_text)\n",
    "tweet_text_list = [x.split(' ') for x in tweet_text_list]\n",
    "max_len = max([len(x) for x in tweet_text_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 64\n",
    "hidden_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = gensim.models.Word2Vec(sentences = tweet_text_list, vector_size = embedding_size,workers = 4, min_count = 1)\n",
    "total_words = len(list(word_embeddings.wv.index_to_key)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('new', 0.9470752477645874),\n",
       " ('us', 0.9453030228614807),\n",
       " ('vaccine', 0.9266708493232727),\n",
       " ('coronavirus', 0.9239075779914856),\n",
       " ('day', 0.922370195388794),\n",
       " ('people', 0.9219273328781128),\n",
       " ('one', 0.9213962554931641),\n",
       " ('time', 0.9146817922592163),\n",
       " ('get', 0.9102112650871277),\n",
       " ('positive', 0.9063314199447632)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings.wv.most_similar('covid', topn=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6533 words are used\n",
      "\n",
      "6533\n",
      "Average words length of all tweets>> 13.114906832298137\n",
      "Maximum words length of a tweet_text >> 40\n",
      "Pad all sequences into size of 18\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df.tweet_text)\n",
    "print(f\"{len(tokenizer.word_index)} words are used\\n\")\n",
    "\n",
    "counts = tokenizer.word_counts\n",
    "print(len(counts))\n",
    "word_size=7000\n",
    "vocab_size = word_size\n",
    "tokenizer = Tokenizer(num_words=word_size)\n",
    "\n",
    "tokenizer.fit_on_texts(df.tweet_text)\n",
    "tokenized = tokenizer.texts_to_sequences(df.tweet_text)\n",
    "lengths = [len(s) for s in tokenized]\n",
    "print(f\"Average words length of all tweets>> {np.mean(lengths)}\")\n",
    "print(f\"Maximum words length of a tweet_text >> {np.max(lengths)}\")\n",
    "\n",
    "sequence_size = 18\n",
    "print(f\"Pad all sequences into size of {sequence_size}\")\n",
    "\n",
    "padded = pad_sequences(tokenized,maxlen=sequence_size,padding='pre',truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[74, 75, 76, 77, 78, 65, 79, 80, 60, 81, 16, 72, 9, 10, 57]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, 74, 75, 76, 77, 78, 65, 79, 80, 60, 81, 16, 72,  9, 10,\n",
       "       57])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((total_words,embedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Matrix Shape :  (6534, 64)\n"
     ]
    }
   ],
   "source": [
    "for idx,word in enumerate(list(word_embeddings.wv.index_to_key)):\n",
    "    emb_vec = word_embeddings.wv[word]\n",
    "    embedding_matrix[idx+1] = emb_vec\n",
    "        \n",
    "print(\"Embedding Matrix Shape : \",embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=[sequence_size]))\n",
    "model.add(Embedding(total_words, embedding_size, weights = [embedding_matrix], input_length = sequence_size, trainable = False))\n",
    "model.add(Bidirectional(LSTM(hidden_size,return_sequences=True)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Bidirectional(LSTM(int(hidden_size/2),return_sequences=True)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Bidirectional(LSTM(int(hidden_size/2),return_sequences=True)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 18, 64)            418176    \n",
      "_________________________________________________________________\n",
      "bidirectional_15 (Bidirectio (None, 18, 256)           197632    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 18, 256)           1024      \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 18, 128)           164352    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 18, 128)           512       \n",
      "_________________________________________________________________\n",
      "bidirectional_17 (Bidirectio (None, 18, 128)           98816     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,503,746\n",
      "Trainable params: 1,084,802\n",
      "Non-trainable params: 418,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1288, 18), (322, 18), (1288,), (322,))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(padded, df.Annotation.values, test_size=0.20)\n",
    "x_train.shape, x_test.shape,y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(df.Annotation.values,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 2s 335ms/step - loss: 0.6175 - accuracy: 0.8155 - val_loss: 0.5920 - val_accuracy: 0.8527\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 1s 268ms/step - loss: 0.4353 - accuracy: 0.8437 - val_loss: 0.5891 - val_accuracy: 0.8527\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 0.4349 - accuracy: 0.8447 - val_loss: 0.6000 - val_accuracy: 0.8527\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.4355 - accuracy: 0.8447 - val_loss: 0.6021 - val_accuracy: 0.8527\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.4239 - accuracy: 0.8447 - val_loss: 0.6059 - val_accuracy: 0.8527\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 1s 258ms/step - loss: 0.4364 - accuracy: 0.8447 - val_loss: 0.6217 - val_accuracy: 0.8527\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 0.4591 - accuracy: 0.8320 - val_loss: 0.6405 - val_accuracy: 0.8527\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.4524 - accuracy: 0.8447 - val_loss: 0.6390 - val_accuracy: 0.8527\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy',mode='min',patience=7,verbose=1)\n",
    "hist = model.fit(x_train,y_train,epochs=100,batch_size = 256, validation_split=0.2, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Confusion Matrix for Train Data : \n",
      "         True Positive =  0            True Negetive =  198\n",
      "        False Positive =  0           False Negetive =  1090\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Total Cases : 1288\n",
      "\n",
      "Accuracy  :  0.8462732919254659\n",
      "\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "confusionMatrixPrint(np.argmax(model(x_train), axis=-1),np.argmax(y_train,axis = -1),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Confusion Matrix for Validation Data \n",
      "\n",
      "         True Positive =  0            True Negetive =  55\n",
      "        False Positive =  0           False Negetive =  267\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "  Total Cases : 322\n",
      "\n",
      "Accuracy  :  0.8291925465838509\n",
      "\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "confusionMatrixPrint(np.argmax(model(x_test), axis=-1),y_test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
