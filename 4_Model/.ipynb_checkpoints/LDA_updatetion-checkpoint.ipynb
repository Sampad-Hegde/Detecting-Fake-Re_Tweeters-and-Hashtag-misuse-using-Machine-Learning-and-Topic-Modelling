{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b279e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1476124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path as syspath\n",
    "from os import path as osPath, getcwd\n",
    "syspath.insert(1, (osPath.dirname(getcwd()).replace('\\\\', '\\\\')) + '\\\\2_Cleaning_Visualization')\n",
    "\n",
    "# noinspection PyUnresolvedReferences\n",
    "from text_cleaning import text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5632d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"C:/Users/Sampad/Desktop/Projects/Capstone/Implimentation/Code/0_DataSet/\"\n",
    "\n",
    "df = pd.read_csv(dataset_path + \"CompleteAnnotated.csv\")\n",
    "\n",
    "df.tweet_text = df.tweet_text.apply(text_clean)\n",
    "\n",
    "all_docs_genuine = []\n",
    "all_docs_fake = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    if df.iloc[i]['Annotation'] == 0:\n",
    "        all_docs_genuine.append(df.iloc[i]['tweet_text'].split())\n",
    "    else:\n",
    "        all_docs_fake.append(df.iloc[i]['tweet_text'].split())\n",
    "\n",
    "num_topics = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04cf0b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_genuinue = Dictionary(all_docs_genuine)\n",
    "\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in all_docs_genuine]\n",
    "\n",
    "lda_gen = gensim.models.ldamodel.LdaModel(common_corpus, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf8975c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_fake = Dictionary(all_docs_fake)\n",
    "\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in all_docs_fake]\n",
    "\n",
    "lda_fake = gensim.models.ldamodel.LdaModel(common_corpus, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c50135cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topic_vector(tweet_text, num_topics, dict_genuine, dict_fake, lda_genuine, lda_fake):\n",
    "\n",
    "   \n",
    "\n",
    "    topic_vector_sparse_genuine = lda_genuine.get_document_topics(tweet_text)\n",
    "    topic_vector_sparse_fake = lda_fake.get_document_topics(tweet_text)\n",
    "\n",
    "\n",
    "    topic_vector = np.zeros(2 * num_topics + 2)\n",
    "\n",
    "    for pair in topic_vector_sparse_genuine:\n",
    "        topic_vector[pair[0]] = pair[1]\n",
    "\n",
    "    for pair in topic_vector_sparse_fake:\n",
    "        topic_vector[num_topics + pair[0]] = pair[1]\n",
    "\n",
    "    return topic_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aafd1d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'covid cases indiandelta variant let fing indiandelta variant'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3afd7b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3160 is out of bounds for axis 1 with size 1509",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-2bf06c909c83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtopic_vecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_topic_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtweet_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdic_genuinue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdic_fake\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlda_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlda_fake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-1521ee215aea>\u001b[0m in \u001b[0;36mgenerate_topic_vector\u001b[1;34m(tweet_text, num_topics, dict_genuine, dict_fake, lda_genuine, lda_fake)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mxf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_fake\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtopic_vector_sparse_genuine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda_genuine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mtopic_vector_sparse_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda_fake\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mget_document_topics\u001b[1;34m(self, bow, minimum_probability, minimum_phi_value, per_word_topics)\u001b[0m\n\u001b[0;32m   1351\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1353\u001b[1;33m         \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1354\u001b[0m         \u001b[0mtopic_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# normalize distribution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[1;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[0mElogthetad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mElogtheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m             \u001b[0mexpElogthetad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpElogtheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m             \u001b[0mexpElogbetad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpElogbeta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m             \u001b[1;31m# The optimal phi_{dwk} is proportional to expElogthetad_k * expElogbetad_kw.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3160 is out of bounds for axis 1 with size 1509"
     ]
    }
   ],
   "source": [
    "topic_vecs = generate_topic_vector(df.tweet_text[0].split(), 10, dic_genuinue, dic_fake, lda_gen, lda_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3223a053",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-37-867b0fe14f7b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-37-867b0fe14f7b>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    lda_gen.\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "lda_gen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "799cd7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.076*\"16\" + 0.033*\"378\" + 0.023*\"712\" + 0.021*\"38\" + 0.018*\"155\" + 0.015*\"963\" + 0.013*\"914\" + 0.012*\"57\" + 0.011*\"113\" + 0.009*\"11\"'),\n",
       " (1,\n",
       "  '0.115*\"16\" + 0.017*\"1365\" + 0.012*\"25\" + 0.012*\"712\" + 0.011*\"484\" + 0.010*\"155\" + 0.010*\"718\" + 0.010*\"724\" + 0.010*\"32\" + 0.009*\"244\"'),\n",
       " (2,\n",
       "  '0.158*\"16\" + 0.014*\"712\" + 0.011*\"38\" + 0.010*\"330\" + 0.010*\"412\" + 0.009*\"210\" + 0.009*\"124\" + 0.009*\"404\" + 0.008*\"53\" + 0.008*\"3\"'),\n",
       " (3,\n",
       "  '0.104*\"16\" + 0.038*\"324\" + 0.017*\"216\" + 0.015*\"712\" + 0.015*\"37\" + 0.012*\"886\" + 0.011*\"187\" + 0.010*\"653\" + 0.010*\"113\" + 0.010*\"835\"'),\n",
       " (4,\n",
       "  '0.086*\"16\" + 0.034*\"37\" + 0.014*\"378\" + 0.014*\"324\" + 0.011*\"31\" + 0.009*\"822\" + 0.009*\"745\" + 0.009*\"38\" + 0.009*\"651\" + 0.009*\"175\"'),\n",
       " (5,\n",
       "  '0.142*\"16\" + 0.031*\"1365\" + 0.023*\"328\" + 0.020*\"38\" + 0.015*\"29\" + 0.012*\"757\" + 0.011*\"77\" + 0.011*\"37\" + 0.011*\"378\" + 0.011*\"361\"'),\n",
       " (6,\n",
       "  '0.112*\"16\" + 0.032*\"712\" + 0.025*\"708\" + 0.022*\"38\" + 0.019*\"289\" + 0.017*\"213\" + 0.015*\"653\" + 0.014*\"29\" + 0.013*\"37\" + 0.013*\"227\"'),\n",
       " (7,\n",
       "  '0.102*\"16\" + 0.035*\"712\" + 0.035*\"11\" + 0.023*\"170\" + 0.015*\"289\" + 0.013*\"37\" + 0.011*\"485\" + 0.009*\"77\" + 0.009*\"724\" + 0.009*\"113\"'),\n",
       " (8,\n",
       "  '0.119*\"16\" + 0.019*\"37\" + 0.012*\"183\" + 0.010*\"1026\" + 0.009*\"324\" + 0.009*\"550\" + 0.008*\"190\" + 0.008*\"688\" + 0.007*\"629\" + 0.007*\"11\"'),\n",
       " (9,\n",
       "  '0.068*\"16\" + 0.026*\"712\" + 0.025*\"1274\" + 0.021*\"1260\" + 0.013*\"61\" + 0.013*\"3\" + 0.013*\"482\" + 0.011*\"324\" + 0.011*\"1\" + 0.010*\"190\"')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_gen.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cc722c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
